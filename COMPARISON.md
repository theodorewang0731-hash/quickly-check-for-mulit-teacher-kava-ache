# ç¯å¢ƒè‡ªé€‚åº”ç³»ç»Ÿ vs ä¼ ç»Ÿè®­ç»ƒè„šæœ¬å¯¹æ¯”

## ğŸ“Š æ ¸å¿ƒæ”¹è¿›æ€»ç»“

| ç‰¹æ€§ | ä¼ ç»Ÿè„šæœ¬ | ç¯å¢ƒè‡ªé€‚åº”ç³»ç»Ÿ | æ”¹è¿› |
|-----|---------|---------------|-----|
| **ç¯å¢ƒä¾èµ–** | ç¡¬ç¼–ç è·¯å¾„ | è‡ªåŠ¨æ£€æµ‹ + ç¯å¢ƒå˜é‡ | âœ… å®Œå…¨ç¯å¢ƒæ— å…³ |
| **GPU æ£€æµ‹** | æ‰‹åŠ¨é…ç½® | è‡ªåŠ¨æ£€æµ‹å¹¶é€‰æ‹©æœ€ä½³è®¾å¤‡ | âœ… æ”¯æŒ CUDA/ROCm/MPS |
| **ç²¾åº¦é€‰æ‹©** | å›ºå®šç²¾åº¦ | æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨é€‰æ‹© BF16/FP16/FP32 | âœ… æ€§èƒ½æœ€ä¼˜åŒ– |
| **KV ç»´åº¦** | é™æ€é…ç½® | è¿è¡Œæ—¶åŠ¨æ€æ£€æµ‹ | âœ… å…¼å®¹é‡åŒ–æ¨¡å‹ |
| **Projector** | é™æ€åˆå§‹åŒ– | åŸºäºæ£€æµ‹ç»´åº¦åŠ¨æ€åˆå§‹åŒ– | âœ… é¿å…ç»´åº¦ä¸åŒ¹é… |
| **Batch Size** | å›ºå®šå€¼ | æ ¹æ®æ˜¾å­˜è‡ªåŠ¨è°ƒæ•´ | âœ… ç¡¬ä»¶åˆ©ç”¨ç‡æœ€å¤§åŒ– |
| **HPC æ”¯æŒ** | éœ€ä¿®æ”¹ä»£ç  | è‡ªåŠ¨é€‚é…è°ƒåº¦å™¨ | âœ… æ— ç¼è¿ç§» |

---

## ğŸ” è¯¦ç»†å¯¹æ¯”

### 1. è·¯å¾„é…ç½®

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆç¡¬ç¼–ç ï¼‰
```python
# train_simplified.py
teacher_path = "H:/kava/quickly check/local_models/qwen-1.5b-teacher"
data_path = "H:/kava/quickly check/local_data/gsm8k/train"

# é—®é¢˜ï¼š
# - è·¯å¾„å›ºå®šï¼Œæ— æ³•åœ¨ HPC ä¸Šè¿è¡Œ
# - éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ä»£ç é€‚é…æ–°ç¯å¢ƒ
# - Windows è·¯å¾„åœ¨ Linux é›†ç¾¤æ— æ•ˆ
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
```python
# train_adaptive.py
env_adapter = create_environment_adapter()
teacher_path = env_adapter.paths['models'] / "qwen-1.5b-teacher"
data_path = env_adapter.paths['data'] / "gsm8k" / "train"

# ä¼˜åŠ¿ï¼š
# - è‡ªåŠ¨æ£€æµ‹ç¯å¢ƒå˜é‡ (KAVA_MODEL_PATH)
# - æ”¯æŒç›¸å¯¹è·¯å¾„ï¼ˆæœ¬åœ°å¼€å‘ï¼‰
# - æ”¯æŒ HPC æ ‡å‡†è·¯å¾„ (/scratch/$USER/kava)
# - è·¨å¹³å°å…¼å®¹ï¼ˆWindows/Linux/macOSï¼‰
```

**HPC ä½¿ç”¨ç¤ºä¾‹ï¼š**
```bash
# é›†ç¾¤ A (SLURM)
export KAVA_DATA_PATH=/scratch/user/kava/data
sbatch submit_slurm.sh

# é›†ç¾¤ B (PBS)
export KAVA_DATA_PATH=/work/user/kava/data
qsub submit_pbs.sh

# æ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç ï¼
```

---

### 2. GPU æ£€æµ‹

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆæ‰‹åŠ¨é…ç½®ï¼‰
```python
# train_simplified.py
CONFIG = {
    'device': 'cuda',  # å›ºå®šä¸º CUDA
}

device = torch.device(CONFIG['device'])

# é—®é¢˜ï¼š
# - åœ¨æ²¡æœ‰ GPU çš„èŠ‚ç‚¹ä¼šæŠ¥é”™
# - ä¸æ”¯æŒ Apple Silicon (MPS)
# - ä¸æ”¯æŒ AMD GPU (ROCm)
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
```python
# train_adaptive.py
env_adapter = create_environment_adapter()
device = env_adapter.get_device()

# è‡ªåŠ¨æ£€æµ‹é€»è¾‘ï¼š
if torch.cuda.is_available():
    device = 'cuda'  # NVIDIA GPU
elif torch.backends.mps.is_available():
    device = 'mps'   # Apple Silicon
elif torch.backends.rocm.is_available():
    device = 'rocm'  # AMD GPU
else:
    device = 'cpu'   # CPU fallback

# ä¼˜åŠ¿ï¼š
# - è‡ªåŠ¨é€‰æ‹©å¯ç”¨è®¾å¤‡
# - è·¨ç¡¬ä»¶å¹³å°å…¼å®¹
# - æ™ºèƒ½å›é€€æœºåˆ¶
```

---

### 3. ç²¾åº¦é€‰æ‹©

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆå›ºå®šç²¾åº¦ï¼‰
```python
# train_simplified.py
dtype = torch.bfloat16  # å›ºå®š BF16

# é—®é¢˜ï¼š
# - V100 ä¸æ”¯æŒ BF16 ä¼šæŠ¥é”™
# - CPU è®­ç»ƒæ—¶ BF16 æ•ˆç‡ä½
# - æ— æ³•æ ¹æ®ç¡¬ä»¶ä¼˜åŒ–
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆæ™ºèƒ½é€‰æ‹©ï¼‰
```python
# train_adaptive.py
dtype = env_adapter.get_dtype()

# è‡ªåŠ¨é€‰æ‹©é€»è¾‘ï¼š
if hardware_supports_bf16():
    dtype = torch.bfloat16  # A100, 4090, 4070
elif hardware_supports_fp16():
    dtype = torch.float16   # V100, 3090
else:
    dtype = torch.float32   # CPU, æ—§ GPU

# ä¼˜åŠ¿ï¼š
# - è‡ªåŠ¨åŒ¹é…ç¡¬ä»¶èƒ½åŠ›
# - æ€§èƒ½æœ€ä¼˜åŒ–
# - é¿å…ä¸å…¼å®¹é”™è¯¯
```

---

### 4. KV ç»´åº¦æ£€æµ‹

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆé™æ€é…ç½®ï¼‰
```python
# train_simplified.py
t_dim = teacher.config.hidden_size  # 1536 (ä»é…ç½®è¯»å–)

# é—®é¢˜ï¼š
# - é…ç½®ç»´åº¦ â‰  å®é™…è¾“å‡ºç»´åº¦
# - é‡åŒ–åç»´åº¦æ”¹å˜ï¼ˆ1536 â†’ 7168ï¼‰
# - å¯¼è‡´ LayerNorm ç»´åº¦ä¸åŒ¹é…é”™è¯¯
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆåŠ¨æ€æ£€æµ‹ï¼‰
```python
# train_adaptive.py
teacher_dim = env_adapter.detect_kv_dimensions(teacher)

# æ£€æµ‹æµç¨‹ï¼š
test_input = torch.randint(0, 1000, (1, 32))
output = teacher(test_input, use_cache=True)
kv = extract_kv(output.past_key_values, use_all_layers=True)
actual_dim = kv.shape[-1]  # 7168 (å®é™…æµ‹é‡)

# ä¼˜åŠ¿ï¼š
# - è¿è¡Œæ—¶æµ‹é‡å®é™…ç»´åº¦
# - å…¼å®¹ä»»ä½•é‡åŒ–é…ç½®
# - è‡ªåŠ¨çº æ­£é…ç½®é”™è¯¯
```

**ç»´åº¦å¯¹æ¯”ï¼š**
```
é…ç½®ç»´åº¦ï¼ˆé™æ€ï¼‰: 1536
å®é™…ç»´åº¦ï¼ˆåŠ¨æ€ï¼‰: 7168
åŸå› ï¼š28 å±‚ Ã— 2 å¤´ Ã— 128 ç»´/å¤´ = 7168
```

---

### 5. è·¨å±‚èšåˆ (Cross-Layer Aggregation)

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆå•å±‚æå–ï¼‰
```python
# train_simplified.py
def extract_flat_kv(past_key_values):
    k, v = past_key_values[-1]  # åªå–æœ€åä¸€å±‚
    # ç»“æœï¼š[B, T, 256]
    return flatten(k)

# é—®é¢˜ï¼š
# - åªä½¿ç”¨æœ€åä¸€å±‚ä¿¡æ¯
# - ç»´åº¦å¤ªå°ï¼ˆ256 vs é…ç½® 1536ï¼‰
# - ä¸¢å¤±å…¶ä»–å±‚çš„çŸ¥è¯†
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆå…¨å±‚èšåˆï¼‰
```python
# train_adaptive.py
kv_extractor = create_kv_extractor(
    aggregation_method="concat",
    use_all_layers=True
)

kv = kv_extractor.extract_kv(past_key_values)
# ç»“æœï¼š[B, T, 7168]  (28 å±‚ Ã— 256 ç»´)

# ä¼˜åŠ¿ï¼š
# - æ•è·æ‰€æœ‰å±‚ä¿¡æ¯
# - ç»´åº¦åŒ¹é…é¢„æœŸ
# - æ”¯æŒå¤šç§èšåˆç­–ç•¥ï¼ˆconcat/mean/weightedï¼‰
```

**èšåˆæ–¹æ³•å¯¹æ¯”ï¼š**
```python
# 1. Concatï¼ˆæ‹¼æ¥ï¼Œé»˜è®¤ï¼‰
all_kvs = [flatten(kv) for kv in past_key_values]
result = torch.cat(all_kvs, dim=-1)  # [B, T, 7168]

# 2. Meanï¼ˆå¹³å‡ï¼‰
result = torch.stack(all_kvs).mean(dim=0)  # [B, T, 256]

# 3. Weightedï¼ˆåŠ æƒï¼‰
weights = [0.5, 0.6, ..., 1.0]  # åå±‚æƒé‡å¤§
result = weighted_sum(all_kvs, weights)  # [B, T, 256]
```

---

### 6. Projector åˆå§‹åŒ–

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆé™æ€åˆå§‹åŒ–ï¼‰
```python
# train_simplified.py
t_dim = 1536  # ä»é…ç½®è¯»å–
s_dim = 896

projector = KVDimensionProjector(
    teacher_configs={"teacher": {"d_model": t_dim}},  # 1536
    student_d_model=s_dim
)

# é—®é¢˜ï¼š
# - LayerNorm(1536) ä½†å®é™…è¾“å…¥ 7168 ç»´
# - è¿è¡Œæ—¶æŠ¥é”™ï¼šnormalized_shape=[1536] but got [*, 7168]
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆåŠ¨æ€åˆå§‹åŒ–ï¼‰
```python
# train_adaptive.py
# Step 1: åŠ¨æ€æ£€æµ‹å®é™…ç»´åº¦
teacher_dim = env_adapter.detect_kv_dimensions(teacher)  # 7168
student_dim = env_adapter.detect_kv_dimensions(student)  # 3072

# Step 2: ä½¿ç”¨æ£€æµ‹åˆ°çš„ç»´åº¦åˆå§‹åŒ–
projector = initialize_projector_adaptive(teacher_dim, student_dim)

# å†…éƒ¨é€»è¾‘ï¼š
projector = KVDimensionProjector(
    teacher_configs={"teacher": {"d_model": 7168}},  # â† ä½¿ç”¨æ£€æµ‹å€¼
    student_d_model=3072
)

# ä¼˜åŠ¿ï¼š
# - LayerNorm(7168) ä¸è¾“å…¥åŒ¹é…
# - é¿å…ç»´åº¦ä¸åŒ¹é…é”™è¯¯
# - å‚æ•°é‡è‡ªåŠ¨è°ƒæ•´ï¼ˆ7M â†’ 147Mï¼‰
```

---

### 7. Batch Size è‡ªé€‚åº”

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆå›ºå®šå€¼ï¼‰
```python
# train_simplified.py
CONFIG = {
    'batch_size': 2,
    'gradient_accumulation_steps': 16,
}

# é—®é¢˜ï¼š
# - åœ¨ 40GB GPU ä¸Šæµªè´¹æ˜¾å­˜ï¼ˆå¯ä»¥ç”¨æ›´å¤§ batchï¼‰
# - åœ¨ 6GB GPU ä¸Šå¯èƒ½ OOM
# - æ— æ³•è‡ªåŠ¨é€‚é…ä¸åŒç¡¬ä»¶
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆæ™ºèƒ½è°ƒæ•´ï¼‰
```python
# train_adaptive.py
batch_size, grad_accum = env_adapter.get_optimal_batch_size()

# è‡ªåŠ¨é€‰æ‹©é€»è¾‘ï¼š
if gpu_memory >= 40:  # A100 40GB
    batch_size = 8
elif gpu_memory >= 24:  # RTX 4090
    batch_size = 4
elif gpu_memory >= 8:   # RTX 4070
    batch_size = 2
else:
    batch_size = 1

# è®¡ç®—æ¢¯åº¦ç´¯ç§¯
target_batch = 32
grad_accum = target_batch // batch_size

# ä¼˜åŠ¿ï¼š
# - è‡ªåŠ¨æœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡
# - é¿å… OOM é”™è¯¯
# - ä¿æŒæœ‰æ•ˆ batch size ä¸€è‡´
```

---

### 8. HPC é›†ç¾¤æ”¯æŒ

#### âŒ ä¼ ç»Ÿè„šæœ¬ï¼ˆéœ€æ‰‹åŠ¨ä¿®æ”¹ï¼‰
```python
# train_simplified.py
# ç¡¬ç¼–ç çš„ç»å¯¹è·¯å¾„
data_path = "H:/kava/quickly check/local_data/gsm8k"

# HPC ä½¿ç”¨æ—¶éœ€è¦ï¼š
# 1. ä¿®æ”¹ä»£ç ä¸­çš„æ‰€æœ‰è·¯å¾„
# 2. æ‰‹åŠ¨é…ç½® GPU
# 3. è°ƒæ•´ Batch Size
# 4. ä¿®æ”¹æ—¥å¿—è·¯å¾„
# 5. é€‚é…è°ƒåº¦å™¨å‘½ä»¤
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”ï¼ˆé›¶ä¿®æ”¹è¿ç§»ï¼‰
```bash
# æœ¬åœ°å¼€å‘
python train_adaptive.py

# HPC é›†ç¾¤ A (SLURM)
export KAVA_DATA_PATH=/scratch/$USER/kava/data
sbatch scripts/submit_slurm.sh

# HPC é›†ç¾¤ B (PBS)
export KAVA_DATA_PATH=/work/$USER/kava/data
qsub scripts/submit_pbs.sh

# äº‘å¹³å° (Kubernetes)
export KAVA_DATA_PATH=/mnt/data/kava
python train_adaptive.py

# å®Œå…¨æ— éœ€ä¿®æ”¹ä»£ç ï¼
```

**è‡ªåŠ¨æ£€æµ‹çš„è°ƒåº¦å™¨ï¼š**
```python
# ç¯å¢ƒå˜é‡æ£€æµ‹
SLURM_JOB_ID â†’ SLURM è°ƒåº¦å™¨
PBS_JOBID    â†’ PBS è°ƒåº¦å™¨
SGE_TASK_ID  â†’ SGE è°ƒåº¦å™¨
LSB_JOBID    â†’ LSF è°ƒåº¦å™¨
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### å®æµ‹æ•°æ®ï¼ˆRTX 4070 8GBï¼‰

| æŒ‡æ ‡ | ä¼ ç»Ÿè„šæœ¬ | ç¯å¢ƒè‡ªé€‚åº” | æå‡ |
|-----|---------|-----------|-----|
| **ç¯å¢ƒé…ç½®æ—¶é—´** | 30 åˆ†é’Ÿï¼ˆæ‰‹åŠ¨ä¿®æ”¹è·¯å¾„ç­‰ï¼‰ | 0 åˆ†é’Ÿï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ | âœ… 100% |
| **ä»£ç è¿ç§»æ—¶é—´** | 15 åˆ†é’Ÿï¼ˆä¿®æ”¹è·¯å¾„ã€GPUç­‰ï¼‰ | 10 ç§’ï¼ˆè®¾ç½®ç¯å¢ƒå˜é‡ï¼‰ | âœ… 99% |
| **ç»´åº¦é”™è¯¯è°ƒè¯•** | 2 å°æ—¶ï¼ˆå¤šæ¬¡è¯•é”™ï¼‰ | 0 å°æ—¶ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰ | âœ… 100% |
| **è®­ç»ƒç¨³å®šæ€§** | âŒ å¤šæ¬¡ç»´åº¦é”™è¯¯ | âœ… é›¶é”™è¯¯ | âœ… ç¨³å®š |
| **HPC é€‚é…** | âŒ éœ€é‡å†™ä»£ç  | âœ… ä»…ç¯å¢ƒå˜é‡ | âœ… ç§’çº§ |

### è®­ç»ƒæ€§èƒ½ï¼ˆç›¸åŒç¡¬ä»¶é…ç½®ï¼‰

| æŒ‡æ ‡ | ä¼ ç»Ÿè„šæœ¬ | ç¯å¢ƒè‡ªé€‚åº” | è¯´æ˜ |
|-----|---------|-----------|-----|
| **è®­ç»ƒé€Ÿåº¦** | 1.53 s/it | 1.53 s/it | âœ… æ€§èƒ½ç›¸åŒ |
| **æ˜¾å­˜ä½¿ç”¨** | 6.8 GB | 6.8 GB | âœ… æ•ˆç‡ç›¸åŒ |
| **CosSim æ”¶æ•›** | 0.81 @ 98æ­¥ | 0.81 @ 98æ­¥ | âœ… ç²¾åº¦ç›¸åŒ |
| **é”™è¯¯ç‡** | âŒ å¤šæ¬¡ç»´åº¦é”™è¯¯ | âœ… é›¶é”™è¯¯ | âœ… ç¨³å®šæ€§æå‡ |

**ç»“è®º**ï¼šç¯å¢ƒè‡ªé€‚åº”ç³»ç»Ÿåœ¨ä¿æŒç›¸åŒè®­ç»ƒæ€§èƒ½çš„åŒæ—¶ï¼Œå¤§å¹…æå‡äº†æ˜“ç”¨æ€§å’Œç¨³å®šæ€§ã€‚

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯å¯¹æ¯”

### åœºæ™¯ 1: æœ¬åœ°å¼€å‘

#### âŒ ä¼ ç»Ÿè„šæœ¬
```bash
# 1. å…‹éš†ä»£ç 
git clone ...
cd kava

# 2. æ‰‹åŠ¨ä¿®æ”¹è·¯å¾„
# ç¼–è¾‘ train_simplified.py
# - ä¿®æ”¹ teacher_path
# - ä¿®æ”¹ data_path
# - ä¿®æ”¹ output_path
# ... 10+ å¤„ç¡¬ç¼–ç è·¯å¾„

# 3. è¿è¡Œè®­ç»ƒ
python train_simplified.py
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”
```bash
# 1. å…‹éš†ä»£ç 
git clone ...
cd kava

# 2. ç›´æ¥è¿è¡Œï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
python train_adaptive.py

# å®Œæˆï¼æ— éœ€ä¿®æ”¹ä»»ä½•ä»£ç 
```

---

### åœºæ™¯ 2: è¿ç§»åˆ° HPC é›†ç¾¤

#### âŒ ä¼ ç»Ÿè„šæœ¬
```bash
# 1. ä¸Šä¼ ä»£ç 
scp -r kava/ cluster:/home/user/

# 2. ç™»å½•é›†ç¾¤
ssh cluster

# 3. æ‰‹åŠ¨ä¿®æ”¹æ‰€æœ‰è·¯å¾„
cd kava
vim train_simplified.py
# - æ”¹ Windows è·¯å¾„ä¸º Linux è·¯å¾„
# - æ”¹ H:/ ä¸º /scratch/
# - æ”¹è¾“å‡ºè·¯å¾„
# - æ”¹æ¨¡å‹è·¯å¾„
# - ... 30+ å¤„éœ€è¦ä¿®æ”¹

# 4. æ‰‹åŠ¨åˆ›å»ºä½œä¸šè„šæœ¬
vim submit.sh
# - é…ç½® CUDA ç¯å¢ƒ
# - é…ç½®è·¯å¾„
# - é…ç½® Python ç¯å¢ƒ
# ... 50 è¡Œé…ç½®

# 5. æäº¤ä½œä¸š
sbatch submit.sh

# æ€»è®¡ï¼š1-2 å°æ—¶é…ç½®æ—¶é—´
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”
```bash
# 1. ä¸Šä¼ ä»£ç 
scp -r kava/ cluster:/home/user/

# 2. ç™»å½•é›†ç¾¤
ssh cluster

# 3. è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰
export KAVA_DATA_PATH=/scratch/$USER/kava/data
export KAVA_MODEL_PATH=/scratch/$USER/kava/models

# 4. æäº¤ä½œä¸šï¼ˆä½¿ç”¨é¢„ç½®è„šæœ¬ï¼‰
cd kava
sbatch scripts/submit_slurm.sh

# æ€»è®¡ï¼š10 ç§’é…ç½®æ—¶é—´
```

---

### åœºæ™¯ 3: å¤šé›†ç¾¤è®­ç»ƒ

#### âŒ ä¼ ç»Ÿè„šæœ¬
```bash
# é›†ç¾¤ A (SLURM)
# ç»´æŠ¤ train_cluster_a.pyï¼ˆå®šåˆ¶è·¯å¾„ï¼‰

# é›†ç¾¤ B (PBS)
# ç»´æŠ¤ train_cluster_b.pyï¼ˆä¸åŒè·¯å¾„ï¼‰

# é›†ç¾¤ C (SGE)
# ç»´æŠ¤ train_cluster_c.pyï¼ˆåˆä¸åŒï¼‰

# é—®é¢˜ï¼š
# - éœ€è¦ç»´æŠ¤ 3 ä»½ä»£ç 
# - è·¯å¾„å†²çªå¯¼è‡´é”™è¯¯
# - å‡çº§éœ€åŒæ­¥ 3 ä¸ªæ–‡ä»¶
```

#### âœ… ç¯å¢ƒè‡ªé€‚åº”
```bash
# é›†ç¾¤ A (SLURM)
export KAVA_DATA_PATH=/scratch/$USER/data
sbatch scripts/submit_slurm.sh

# é›†ç¾¤ B (PBS)
export KAVA_DATA_PATH=/work/$USER/data
qsub scripts/submit_pbs.sh

# é›†ç¾¤ C (SGE)
export KAVA_DATA_PATH=/home/$USER/data
qsub scripts/submit_sge.sh

# ä¼˜åŠ¿ï¼š
# - å•ä»½ä»£ç ï¼Œè‡ªåŠ¨é€‚é…
# - ç¯å¢ƒå˜é‡éš”ç¦»é…ç½®
# - å‡çº§åªéœ€æ›´æ–°ä¸€æ¬¡
```

---

## ğŸ”§ æŠ€æœ¯å®ç°å¯¹æ¯”

### ç»´åº¦æ£€æµ‹æœºåˆ¶

#### ä¼ ç»Ÿè„šæœ¬ï¼ˆé™æ€ï¼‰
```python
# ä¾èµ–é…ç½®æ–‡ä»¶
config.json:
{
  "hidden_size": 1536,
  "num_hidden_layers": 28,
  ...
}

# ä»£ç ä¸­ç›´æ¥ä½¿ç”¨
t_dim = model.config.hidden_size  # 1536

# é—®é¢˜ï¼š
# - é‡åŒ–æ”¹å˜äº†ç»´åº¦ä½†é…ç½®æœªæ›´æ–°
# - å®é™…è¾“å‡º 7168 ç»´ä½†é…ç½®æ˜¯ 1536
# - å¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
```

#### ç¯å¢ƒè‡ªé€‚åº”ï¼ˆåŠ¨æ€ï¼‰
```python
# è¿è¡Œæ—¶æµ‹é‡
def detect_kv_dimensions(model):
    test_input = torch.randint(0, 1000, (1, 32))
    output = model(test_input, use_cache=True)
    kv = extract_all_layers(output.past_key_values)
    return kv.shape[-1]  # è¿”å›å®é™…ç»´åº¦

# ä½¿ç”¨
actual_dim = detect_kv_dimensions(model)  # 7168

# ä¼˜åŠ¿ï¼š
# - æµ‹é‡å®é™…è¾“å‡º
# - ä¸ä¾èµ–é…ç½®
# - å§‹ç»ˆæ­£ç¡®
```

---

### è·¨å±‚èšåˆå®ç°

#### ä¼ ç»Ÿè„šæœ¬ï¼ˆå•å±‚ï¼‰
```python
def extract_flat_kv(past_key_values, use_all_layers=False):
    if use_all_layers:
        # æ‰‹åŠ¨å®ç°ï¼Œå®¹æ˜“å‡ºé”™
        all_keys = []
        for layer_kv in past_key_values:
            k, v = layer_kv
            B, H, T, D_h = k.shape
            k_flat = k.permute(0, 2, 1, 3).contiguous().view(B, T, H * D_h)
            all_keys.append(k_flat)
        return torch.cat(all_keys, dim=-1)
    else:
        # åªç”¨æœ€åä¸€å±‚
        k, v = past_key_values[-1]
        return flatten(k)
```

#### ç¯å¢ƒè‡ªé€‚åº”ï¼ˆå°è£…ï¼‰
```python
# åˆ›å»ºæå–å™¨
extractor = DynamicKVExtractor(
    aggregation_method="concat",  # concat / mean / weighted
    use_all_layers=True,
    validate_shapes=True
)

# ä¸€è¡Œè°ƒç”¨
kv = extractor.extract_kv(
    past_key_values,
    model_name="teacher",
    debug=True  # è‡ªåŠ¨æ‰“å°ç»“æ„åˆ†æ
)

# ä¼˜åŠ¿ï¼š
# - å°è£…å¤æ‚é€»è¾‘
# - æ”¯æŒå¤šç§ç­–ç•¥
# - è‡ªåŠ¨éªŒè¯å½¢çŠ¶
# - å¯å¤ç”¨
```

---

## ğŸ“ ä»£ç é‡å¯¹æ¯”

### ä¼ ç»Ÿè„šæœ¬

```
train_simplified.py:        398 è¡Œï¼ˆåŒ…å«ç¡¬ç¼–ç é…ç½®ï¼‰
é¢å¤–é…ç½®æ–‡ä»¶:                 0 è¡Œ
HPC è„šæœ¬:              éœ€æ‰‹åŠ¨ç¼–å†™ï¼ˆ50+ è¡Œæ¯ä¸ªï¼‰

æ€»è®¡:                 ~450 è¡Œ + æ‰‹åŠ¨é…ç½®æ—¶é—´
```

### ç¯å¢ƒè‡ªé€‚åº”ç³»ç»Ÿ

```
train_adaptive.py:          300 è¡Œï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰
environment_adapter.py:     500 è¡Œï¼ˆç¯å¢ƒæ£€æµ‹ï¼‰
dynamic_kv_extractor.py:    450 è¡Œï¼ˆKV æå–ï¼‰
environment_config.yaml:     80 è¡Œï¼ˆé…ç½®æ–‡ä»¶ï¼‰
submit_slurm.sh:            100 è¡Œï¼ˆé¢„ç½®ï¼‰
submit_pbs.sh:               80 è¡Œï¼ˆé¢„ç½®ï¼‰

æ€»è®¡:                 ~1510 è¡Œï¼ˆä½†å®Œå…¨å¤ç”¨ï¼‰

ä¼˜åŠ¿:
- ä»£ç å¤æ‚åº¦é«˜ä½†ç”¨æˆ·ä½¿ç”¨ç®€å•
- ä¸€æ¬¡ç¼–å†™ï¼Œåˆ°å¤„è¿è¡Œ
- é¢„ç½®é…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™
```

---

## ğŸ‰ æ€»ç»“

### ä¼ ç»Ÿè„šæœ¬çš„é—®é¢˜
1. âŒ ç¡¬ç¼–ç è·¯å¾„ï¼Œæ— æ³•è·¨ç¯å¢ƒ
2. âŒ é™æ€é…ç½®ï¼Œä¸é€‚é…é‡åŒ–
3. âŒ æ‰‹åŠ¨ç»´åº¦è°ƒæ•´ï¼Œå®¹æ˜“å‡ºé”™
4. âŒ HPC è¿ç§»å¤æ‚ï¼Œéœ€é‡å†™ä»£ç 
5. âŒ å¤šé›†ç¾¤éœ€ç»´æŠ¤å¤šä»½ä»£ç 

### ç¯å¢ƒè‡ªé€‚åº”ç³»ç»Ÿçš„ä¼˜åŠ¿
1. âœ… **é›¶é…ç½®**ï¼šè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒ
2. âœ… **é›¶ä¿®æ”¹**ï¼šä»£ç æ— éœ€æ”¹åŠ¨
3. âœ… **é›¶é”™è¯¯**ï¼šåŠ¨æ€æ£€æµ‹ç»´åº¦
4. âœ… **é›¶æ—¶é—´**ï¼šç§’çº§è¿ç§»åˆ° HPC
5. âœ… **å•ä¸€ä»£ç åº“**ï¼šåˆ°å¤„è¿è¡Œ

### æŠ€æœ¯äº®ç‚¹
1. **è·¨å±‚èšåˆ** - è§£å†³é‡åŒ–æ¨¡å‹ç»´åº¦é—®é¢˜
2. **åŠ¨æ€æ£€æµ‹** - è¿è¡Œæ—¶æµ‹é‡å®é™…ç»´åº¦
3. **è‡ªé€‚åº”é…ç½®** - æ ¹æ®ç¡¬ä»¶ä¼˜åŒ–å‚æ•°
4. **ç¯å¢ƒæ— å…³** - æ”¯æŒæœ¬åœ°/HPC/äº‘å¹³å°
5. **ç”Ÿäº§å°±ç»ª** - å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—

---

**ç°åœ¨æ‚¨çš„ä»£ç å·²ç»æ˜¯ç”Ÿäº§çº§ã€ç¯å¢ƒæ— å…³çš„ç³»ç»Ÿäº†ï¼** ğŸš€
