"""
HeadwiseMapProjector: Anti-Flatten ç»“æ„åŒ–æŠ•å½±

åšæŒ 5D è¾“å…¥è¾“å‡º [B, L, H, T, D]ï¼Œä¸è¿›è¡Œ flatten æ“ä½œã€‚
æ”¯æŒå…±äº«æˆ– per-head çš„ç»´åº¦æŠ•å½±ã€‚

âœ¨ v4.0 æ›´æ–°ï¼š
- æ·»åŠ  init_uniform å‚æ•°ï¼Œæ”¯æŒå‡åŒ€åˆå§‹åŒ– head_mixer
- ä¸º baseline å¯¹æ¯”ä¿ç•™äº†æ¸…æ™°çš„åˆå§‹åŒ–ç­–ç•¥
"""
import torch
import torch.nn as nn
from typing import Optional


class HeadwiseMapProjector(nn.Module):
    """
    ç»“æ„åŒ– KV æŠ•å½±å™¨ï¼šTeacher â†’ Student
    
    è¾“å…¥è¾“å‡ºä¸¥æ ¼ä¿æŒ 5D å½¢çŠ¶ [B, L, H, T, D]
    ä¸è¿›è¡Œä»»ä½• flatten æ“ä½œï¼ˆAnti-Flatten è®¾è®¡ï¼‰
    
    Args:
        H_t: Teacher çš„æ³¨æ„åŠ›å¤´æ•°
        H_s: Student çš„æ³¨æ„åŠ›å¤´æ•°
        D_t: Teacher æ¯ä¸ªå¤´çš„ç»´åº¦
        D_s: Student æ¯ä¸ªå¤´çš„ç»´åº¦
        share_dim_proj: æ˜¯å¦åœ¨æ‰€æœ‰å¤´ä¹‹é—´å…±äº«ç»´åº¦æŠ•å½±çŸ©é˜µ
        init_uniform: æ˜¯å¦ä½¿ç”¨å‡åŒ€åˆå§‹åŒ– head_mixerï¼ˆæ¨èç”¨äºå¿«é€Ÿæ”¶æ•›ï¼‰
    
    Example:
        >>> projector = HeadwiseMapProjector(
        ...     H_t=32, H_s=16, D_t=128, D_s=64,
        ...     share_dim_proj=True, init_uniform=True
        ... )
        >>> k_t = torch.randn(2, 12, 32, 512, 128)  # [B, L, H_t, T, D_t]
        >>> k_s = projector(k_t)                     # [B, L, H_s, T, D_s]
    """
    
    def __init__(
        self,
        H_t: int,
        H_s: int,
        D_t: int,
        D_s: int,
        share_dim_proj: bool = True,
        init_uniform: bool = True
    ):
        super().__init__()
        self.H_t = H_t
        self.H_s = H_s
        self.D_t = D_t
        self.D_s = D_s
        self.share_dim_proj = share_dim_proj
        
        # Head æ··åˆå™¨ï¼šå­¦ä¹ å¦‚ä½•å°† H_t ä¸ªå¤´æ˜ å°„åˆ° H_s ä¸ªå¤´
        self.head_mixer = nn.Linear(H_t, H_s, bias=False)
        
        # ç»´åº¦æŠ•å½±å™¨ï¼šD_t â†’ D_s
        if share_dim_proj:
            # æ‰€æœ‰å¤´å…±äº«åŒä¸€ä¸ªæŠ•å½±çŸ©é˜µï¼ˆå‚æ•°å°‘ï¼‰
            self.dim_proj = nn.Linear(D_t, D_s, bias=False)
        else:
            # æ¯ä¸ª student head æœ‰ç‹¬ç«‹çš„æŠ•å½±çŸ©é˜µï¼ˆè¡¨è¾¾åŠ›å¼ºï¼‰
            self.dim_proj = nn.ModuleList([
                nn.Linear(D_t, D_s, bias=False) for _ in range(H_s)
            ])
        
        # å¯é€‰ï¼šå‡åŒ€åˆå§‹åŒ– head_mixer
        if init_uniform:
            self.init_uniform_head_mixer()
    
    def init_uniform_head_mixer(self):
        """
        å‡åŒ€åˆå§‹åŒ– head_mixer æƒé‡
        
        å°† Teacher çš„å¤´å‡åŒ€åˆ†é…åˆ° Student çš„å¤´ï¼š
        - Student head 0 â†’ Teacher heads [0, H_t//H_s)
        - Student head 1 â†’ Teacher heads [H_t//H_s, 2*H_t//H_s)
        - ...
        
        è¿™æ ·åˆå§‹åŒ–èƒ½æä¾›ä¸€ä¸ª"åˆç†çš„èµ·ç‚¹"ï¼Œé¿å…éšæœºåˆå§‹åŒ–æ—¶å¯èƒ½çš„ä¸ç¨³å®šã€‚
        """
        with torch.no_grad():
            w = torch.zeros(self.H_s, self.H_t)
            for h_s in range(self.H_s):
                # è®¡ç®—è¿™ä¸ª student head å¯¹åº”çš„ teacher heads åŒºé—´
                start = int(h_s * self.H_t / self.H_s)
                end = int((h_s + 1) * self.H_t / self.H_s)
                # å‡åŒ€æƒé‡
                w[h_s, start:end] = 1.0 / max(1, end - start)
            self.head_mixer.weight.copy_(w)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­ï¼šä¿æŒ 5D ç»“æ„
        
        Args:
            x: Teacher KVï¼Œå½¢çŠ¶ [B, L, H_t, T, D_t]
        
        Returns:
            x_proj: Student KVï¼Œå½¢çŠ¶ [B, L, H_s, T, D_s]
        """
        B, L, H_t, T, D_t = x.shape
        assert H_t == self.H_t and D_t == self.D_t, \
            f"è¾“å…¥å½¢çŠ¶ä¸åŒ¹é…ï¼šæœŸæœ› H_t={self.H_t}, D_t={self.D_t}ï¼Œå®é™… H_t={H_t}, D_t={D_t}"
        
        # Step 1: Head æ··åˆ [B, L, H_t, T, D_t] â†’ [B, L, H_s, T, D_t]
        # å°† head ç»´åº¦ç§»åˆ°æœ€åï¼Œåšçº¿æ€§å˜æ¢ï¼Œå†ç§»å›æ¥
        x = x.permute(0, 1, 3, 4, 2)  # [B, L, T, D_t, H_t]
        x = self.head_mixer(x)         # [B, L, T, D_t, H_s]
        x = x.permute(0, 1, 4, 2, 3)  # [B, L, H_s, T, D_t]
        
        # Step 2: ç»´åº¦æŠ•å½± [B, L, H_s, T, D_t] â†’ [B, L, H_s, T, D_s]
        if self.share_dim_proj:
            # å…±äº«æŠ•å½±ï¼šç›´æ¥ä½œç”¨åœ¨æœ€åä¸€ç»´
            x = self.dim_proj(x)  # [B, L, H_s, T, D_s]
        else:
            # Per-head æŠ•å½±ï¼šæ¯ä¸ª student head ç‹¬ç«‹æŠ•å½±
            outputs = []
            for h in range(self.H_s):
                x_h = x[:, :, h, :, :]  # [B, L, T, D_t]
                x_h_proj = self.dim_proj[h](x_h)  # [B, L, T, D_s]
                outputs.append(x_h_proj.unsqueeze(2))  # [B, L, 1, T, D_s]
            x = torch.cat(outputs, dim=2)  # [B, L, H_s, T, D_s]
        
        return x


# ===== è¾…åŠ©å‡½æ•°ï¼šæ–¹ä¾¿æ‰¹é‡åˆ›å»º =====

def create_kv_projectors(
    teacher_config,
    student_config,
    share_dim_proj: bool = True,
    init_uniform: bool = True
):
    """
    åˆ›å»º Kã€Vï¼ˆå’Œå¯é€‰çš„ Qï¼‰æŠ•å½±å™¨
    
    Args:
        teacher_config: Teacher æ¨¡å‹é…ç½®ï¼ˆéœ€è¦ num_attention_heads, hidden_sizeï¼‰
        student_config: Student æ¨¡å‹é…ç½®
        share_dim_proj: æ˜¯å¦å…±äº«ç»´åº¦æŠ•å½±
        init_uniform: æ˜¯å¦å‡åŒ€åˆå§‹åŒ–
    
    Returns:
        proj_k, proj_v, proj_q
    """
    H_t = teacher_config.num_attention_heads
    H_s = student_config.num_attention_heads
    D_t = teacher_config.hidden_size // H_t
    D_s = student_config.hidden_size // H_s
    
    proj_k = HeadwiseMapProjector(H_t, H_s, D_t, D_s, share_dim_proj, init_uniform)
    proj_v = HeadwiseMapProjector(H_t, H_s, D_t, D_s, share_dim_proj, init_uniform)
    proj_q = HeadwiseMapProjector(H_t, H_s, D_t, D_s, share_dim_proj, init_uniform)
    
    return proj_k, proj_v, proj_q


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    print("ğŸ§ª æµ‹è¯• HeadwiseMapProjector")
    
    # åˆ›å»ºæŠ•å½±å™¨
    projector = HeadwiseMapProjector(
        H_t=32, H_s=16, D_t=128, D_s=64,
        share_dim_proj=True, init_uniform=True
    )
    
    # æµ‹è¯•è¾“å…¥
    k_t = torch.randn(2, 12, 32, 512, 128)  # [B=2, L=12, H_t=32, T=512, D_t=128]
    print(f"è¾“å…¥å½¢çŠ¶: {k_t.shape}")
    
    # å‰å‘ä¼ æ’­
    k_s = projector(k_t)
    print(f"è¾“å‡ºå½¢çŠ¶: {k_s.shape}")
    print(f"é¢„æœŸå½¢çŠ¶: [2, 12, 16, 512, 64]")
    
    # æ£€æŸ¥åˆå§‹åŒ–
    print(f"\nâœ… head_mixer æƒé‡å‡å€¼: {projector.head_mixer.weight.mean().item():.4f}")
    print(f"âœ… head_mixer æƒé‡æ ‡å‡†å·®: {projector.head_mixer.weight.std().item():.4f}")
    
    # éªŒè¯æ¯ä¸ª student head çš„æƒé‡å’Œä¸º 1ï¼ˆå‡åŒ€åˆå§‹åŒ–ï¼‰
    row_sums = projector.head_mixer.weight.sum(dim=1)
    print(f"âœ… æ¯è¡Œæƒé‡å’Œï¼ˆåº”è¯¥æ¥è¿‘1.0ï¼‰: {row_sums[:5]}")
