# å¤§è§„æ¨¡å¤šæ•™å¸ˆ KV è’¸é¦å®éªŒæŒ‡å—

## ğŸ“‹ å®éªŒæ¦‚è§ˆ

### é…ç½®è§„æ ¼
- **æ•™å¸ˆæ¨¡å‹**ï¼š7B-34B çº§åˆ«ï¼ˆLlama-3.1-8B/70B, Qwen2.5-7B/14B/32Bï¼‰
- **å­¦ç”Ÿæ¨¡å‹**ï¼š1.5B-3B çº§åˆ«ï¼ˆQwen2.5-1.5B/3B, Llama-3.2-3Bï¼‰
- **æ•°æ®é›†**ï¼š
  - åŸºç¡€ï¼šGSM8K + SVAMP + StrategyQA + Math23Kï¼ˆ20% ä¸­æ–‡ï¼‰
  - æ‰©å±•ï¼šMATH subset + ARC-Challenge + HotpotQA
  - æ¯é¢˜åŒé£æ ¼ï¼šCoTï¼ˆé“¾å¼æ¨ç†ï¼‰+ Directï¼ˆç›´æ¥ç­”æ¡ˆï¼‰
- **è¯„æµ‹**ï¼šGSM8K test, MATH500, BBH, GPQA, TruthfulQA, CMMLU, C-Eval

### è®­ç»ƒç­–ç•¥
1. **æ¨¡å‹ç»„åˆ**ï¼ˆæ¨èé¡ºåºï¼‰ï¼š
   - å•å®¶æ—å¤š checkpointï¼šçº¯ Llama æˆ–çº¯ Qwenï¼ˆææ˜“å¯¹é½ï¼Œèµ·æ­¥é¦–é€‰ï¼‰
   - è·¨å®¶æ—å°‘é‡ï¼šQwen + Llamaï¼ˆæœ€ç¨³ï¼Œæ¬¡ä¼˜é€‰æ‹©ï¼‰
   - æ··åˆå¤šæ ·æ€§ï¼š3+ ä¸ªä¸åŒæ¨¡å‹ï¼ˆæµ‹è¯•æé™ï¼‰

2. **è·¯ç”±è®­ç»ƒ**ï¼ˆä¸‰é˜¶æ®µï¼‰ï¼š
   - Stage 1: å›ºå®šæƒé‡ â†’ éªŒè¯åŸºç¡€èåˆ
   - Stage 2: ç›¸ä¼¼åº¦è·¯ç”± â†’ è‡ªåŠ¨æƒé‡åˆ†é…
   - Stage 3: å¯å­¦ä¹ è·¯ç”± â†’ ç«¯åˆ°ç«¯ä¼˜åŒ–

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate kava_env

# éªŒè¯ä¾èµ–
python -c "import transformers, torch, datasets; print('âœ“ Dependencies OK')"

# è®¾ç½® HuggingFace ç¼“å­˜
export HF_HOME="/scratch/$USER/huggingface"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HF_DATASETS_CACHE="$HF_HOME/datasets"
```

### 2. å‡†å¤‡æ•°æ®é›†

```bash
# æ–¹å¼ A: ä½¿ç”¨æ•°æ®é›†åŠ è½½å™¨ï¼ˆæ¨èï¼‰
python -c "
from data.multi_task_dataset import MultiTaskReasoningDataset

loader = MultiTaskReasoningDataset(
    base_datasets=['gsm8k', 'svamp', 'strategyqa'],  # math23k éœ€æœ¬åœ°å‡†å¤‡
    extended_datasets=['math', 'arc_challenge', 'hotpotqa'],
    use_extended=True,
    math23k_ratio=0.2,
    train_samples=15000,
    val_samples=2000,
)

train_ds, val_ds = loader.load_and_prepare()
print(f'âœ“ Train: {len(train_ds)}, Val: {len(val_ds)}')

# ä¿å­˜åˆ°ç£ç›˜
train_ds.save_to_disk('./data/prepared/train')
val_ds.save_to_disk('./data/prepared/val')
"

# æ–¹å¼ B: ç›´æ¥ä½¿ç”¨ HuggingFace Datasets
# è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨åŠ è½½å’Œå¤„ç†
```

### 3. æå–æ•™å¸ˆ KVï¼ˆå¯é€‰ï¼Œæ¨èç¦»çº¿ï¼‰

```bash
# ä¸ºå¤šä¸ªæ•™å¸ˆæ¨¡å‹æå– KV Cache
python scripts/extract_dual_style_kv.py \
    --teacher_models "Qwen/Qwen2.5-7B" "Qwen/Qwen2.5-14B" \
    --student_model "Qwen/Qwen2.5-1.5B" \
    --dataset_path "./data/prepared/train" \
    --output_dir "./kv_cache/qwen_dual_teacher" \
    --output_name "train_kv" \
    --kv_compression "right" \
    --max_length 2048 \
    --device cuda

# éªŒè¯ KV æå–
python -c "
import torch
kv_data = torch.load('./kv_cache/qwen_dual_teacher/train_kv.pt')
print(f'âœ“ Loaded {len(kv_data)} examples with KV cache')
print(f'âœ“ First example keys shape: {kv_data[0][\"teacher_kvs\"][0][\"keys\"].shape}')
"
```

---

## ğŸ“Š å®éªŒåœºæ™¯

### åœºæ™¯ 1: å•å®¶æ—åŒæ•™å¸ˆï¼ˆèµ·æ­¥æ¨èï¼‰

**ç›®æ ‡**ï¼šéªŒè¯åŸºç¡€èåˆï¼Œæœ€æ˜“å¯¹é½

```bash
# çº¯ Qwen å®¶æ—
sbatch --job-name="qwen_dual" \
       --export=STUDENT="Qwen/Qwen2.5-1.5B",TEACHERS="Qwen/Qwen2.5-7B Qwen/Qwen2.5-14B" \
       scripts/run_three_stage_routing.sh

# çº¯ Llama å®¶æ—
sbatch --job-name="llama_dual" \
       --export=STUDENT="meta-llama/Llama-3.2-3B",TEACHERS="meta-llama/Llama-3.1-8B meta-llama/Llama-3.1-70B" \
       scripts/run_three_stage_routing.sh
```

**é¢„æœŸç»“æœ**ï¼š
- Stage 1ï¼ˆå›ºå®šæƒé‡ï¼‰ï¼šå¿«é€Ÿæ”¶æ•›ï¼ŒKV loss < 0.5
- Stage 2ï¼ˆç›¸ä¼¼åº¦è·¯ç”±ï¼‰ï¼šè‡ªåŠ¨æƒé‡æ¥è¿‘ 0.5/0.5ï¼ˆåŒå®¶æ—å·®å¼‚å°ï¼‰
- Stage 3ï¼ˆå¯å­¦ä¹ è·¯ç”±ï¼‰ï¼šè½»å¾®æå‡ï¼Œè·¯ç”±å­¦ä¹ åˆ°ä»»åŠ¡ç‰¹å®šåå¥½

### åœºæ™¯ 2: è·¨å®¶æ—åŒæ•™å¸ˆï¼ˆç¨³å¥é€‰æ‹©ï¼‰

**ç›®æ ‡**ï¼šæµ‹è¯•å¼‚æ„èåˆï¼Œå¹³è¡¡æ€§èƒ½ä¸é²æ£’æ€§

```bash
# Qwen + Llama
sbatch --job-name="cross_family" \
       --export=STUDENT="Qwen/Qwen2.5-1.5B",TEACHERS="Qwen/Qwen2.5-7B meta-llama/Llama-3.1-8B" \
       scripts/run_three_stage_routing.sh
```

**é¢„æœŸç»“æœ**ï¼š
- Stage 1ï¼šæ”¶æ•›è¾ƒæ…¢ï¼ˆå¯¹é½éš¾åº¦å¢åŠ ï¼‰ï¼ŒKV loss 0.5-0.8
- Stage 2ï¼šç›¸ä¼¼åº¦è·¯ç”±æ˜¾è‘—æ”¹å–„ï¼Œæƒé‡åŠ¨æ€è°ƒæ•´ï¼ˆ0.3/0.7 åˆ° 0.6/0.4ï¼‰
- Stage 3ï¼šæ˜æ˜¾æå‡ï¼Œè·¯ç”±ç½‘ç»œå­¦ä¹ åˆ°è·¨æ¶æ„äº’è¡¥æ€§

### åœºæ™¯ 3: å¤šæ•™å¸ˆå¤§è§„æ¨¡ï¼ˆæé™æµ‹è¯•ï¼‰

**ç›®æ ‡**ï¼šæ¢ç´¢å¤šæ ·æ€§æ”¶ç›Šä¸Šé™

```bash
# ä¿®æ”¹ SLURM è„šæœ¬ä¸­çš„é…ç½®
# TEACHER_MODELS="Qwen/Qwen2.5-7B Qwen/Qwen2.5-14B Qwen/Qwen2.5-32B"
# NUM_TEACHERS=3
# FIXED_WEIGHTS="0.33,0.33,0.34"

sbatch scripts/run_large_scale_multi_teacher.sh
```

**é¢„æœŸç»“æœ**ï¼š
- KV loss å¯èƒ½ä¸Šå‡ï¼ˆæ›´å¤šå¯¹é½è¯¯å·®ï¼‰
- æœ€ç»ˆä»»åŠ¡æŒ‡æ ‡å¯èƒ½æå‡ï¼ˆå¤šæ ·æ€§æ”¶ç›Šï¼‰
- éœ€è¦æ›´å¤šè®­ç»ƒè½®æ•°å’Œæ›´å¼ºçš„æ­£åˆ™åŒ–

---

## ğŸ”¬ è·¯ç”±è®­ç»ƒè¯¦è§£

### Stage 1: å›ºå®šæƒé‡

```bash
# æ ¸å¿ƒé…ç½®
FUSION_STRATEGY="fixed"
FIXED_WEIGHTS="0.5,0.5"  # ç­‰æƒé‡

# ç›‘æ§æŒ‡æ ‡
# - train/kv_loss: åº”ç¨³å®šä¸‹é™
# - val/kv_loss: åº”ä½äº 1.0
# - eval/*: ä»»åŠ¡æŒ‡æ ‡åº”è¾¾åˆ°å•æ•™å¸ˆæ°´å¹³

# è°ƒè¯•å»ºè®®
# - å¦‚æœ KV loss > 1.5ï¼šæ£€æŸ¥å¯¹é½æ¨¡å—ï¼ˆlayer_map, head_dimï¼‰
# - å¦‚æœä»»åŠ¡æŒ‡æ ‡ä½ï¼šå¢åŠ  KV_LOSS_WEIGHT æˆ–è°ƒæ•´ LEARNING_RATE
```

### Stage 2: ç›¸ä¼¼åº¦è·¯ç”±

```bash
# æ ¸å¿ƒé…ç½®
FUSION_STRATEGY="similarity"
SIMILARITY_METRIC="cosine"  # æˆ– "dot", "euclidean"
TEMPERATURE=1.0

# ç›‘æ§æŒ‡æ ‡
# - routing/weights_mean: å„æ•™å¸ˆå¹³å‡æƒé‡ï¼ˆåº”åŠ¨æ€å˜åŒ–ï¼‰
# - routing/entropy: è·¯ç”±ç†µï¼ˆ>0.5 è¡¨ç¤ºå¤šæ ·æ€§å¥½ï¼‰
# - val/kv_loss: åº”ä½äº Stage 1

# åˆ†ææŠ€å·§
# æŸ¥çœ‹ TensorBoardï¼š
tensorboard --logdir outputs/three_stage_routing/stage2_similarity

# æ£€æŸ¥æƒé‡åˆ†å¸ƒï¼š
# - åŒå®¶æ—ï¼šæƒé‡æ¥è¿‘å‡åŒ€ï¼ˆ0.5/0.5ï¼‰
# - è·¨å®¶æ—ï¼šæƒé‡åˆ†åŒ–æ˜æ˜¾ï¼ˆ0.3/0.7ï¼‰
# - å¤šæ•™å¸ˆï¼šå‡ºç°"ä¸“å®¶åˆ†å·¥"ï¼ˆæŸäº›æ•™å¸ˆä¸“æ³¨æŸç±»ä»»åŠ¡ï¼‰
```

### Stage 3: å¯å­¦ä¹ è·¯ç”±

```bash
# æ ¸å¿ƒé…ç½®
FUSION_STRATEGY="learnable"
ROUTER_TYPE="mlp"  # æˆ– "gate", "attention"
ROUTER_HIDDEN_DIM=256
ENTROPY_REG_WEIGHT=0.01

# ç›‘æ§æŒ‡æ ‡
# - routing/router_loss: è·¯ç”±ç½‘ç»œæŸå¤±
# - routing/entropy_reg: ç†µæ­£åˆ™åŒ–é¡¹ï¼ˆé˜²æ­¢åç¼©ï¼‰
# - val/task_metrics: æœ€ç»ˆä»»åŠ¡æŒ‡æ ‡ï¼ˆåº”æœ€é«˜ï¼‰

# è¶…å‚æ•°è°ƒä¼˜
# - entropy_reg_weight å¤ªå¤§ â†’ æƒé‡è¿‡äºå‡åŒ€ï¼Œæ”¶ç›Šé™ä½
# - entropy_reg_weight å¤ªå° â†’ æƒé‡åç¼©åˆ°å•ä¸€æ•™å¸ˆ
# - æ¨èèŒƒå›´ï¼š0.001 - 0.05
```

---

## ğŸ“ˆ è¯„æµ‹ä¸åˆ†æ

### è¿è¡Œè¯„æµ‹

```bash
# å•é˜¶æ®µè¯„æµ‹
python evaluation/multi_task_eval.py \
    --model_path "./outputs/three_stage_routing/stage3_learnable/best_model" \
    --eval_datasets gsm8k_test math500 bbh gpqa truthfulqa cmmlu_subset ceval_subset \
    --output_file "./outputs/three_stage_routing/stage3_learnable/eval_results.json"

# æŸ¥çœ‹ç»“æœ
cat outputs/three_stage_routing/stage3_learnable/eval_results.json
```

### å¯¹æ¯”åˆ†æ

```python
# ä¸‰é˜¶æ®µæ€§èƒ½å¯¹æ¯”
import json
import pandas as pd

stages = ['stage1_fixed', 'stage2_similarity', 'stage3_learnable']
results = {}

for stage in stages:
    with open(f'./outputs/three_stage_routing/{stage}/eval_results.json') as f:
        results[stage] = json.load(f)

# è½¬ä¸º DataFrame
data = []
for dataset in results['stage1_fixed'].keys():
    if dataset != 'average':
        row = {'Dataset': dataset}
        for stage in stages:
            row[stage] = results[stage][dataset]['score']
        data.append(row)

df = pd.DataFrame(data)
print(df.to_markdown(index=False))

# è®¡ç®—æå‡
df['Stage2_vs_1'] = df['stage2_similarity'] - df['stage1_fixed']
df['Stage3_vs_2'] = df['stage3_learnable'] - df['stage2_similarity']
print("\næå‡åˆ†æ:")
print(df[['Dataset', 'Stage2_vs_1', 'Stage3_vs_2']].to_markdown(index=False))
```

### å…³é”®æŒ‡æ ‡è§£è¯»

| æŒ‡æ ‡ | è‰¯å¥½èŒƒå›´ | è¯´æ˜ |
|------|---------|------|
| GSM8K test | 60-80% | æ•°å­¦æ¨ç†èƒ½åŠ› |
| MATH500 | 30-50% | é«˜éš¾åº¦æ•°å­¦ |
| BBH | 50-70% | å¤šæ ·åŒ–æ¨ç† |
| GPQA | 30-40% | ç§‘å­¦çŸ¥è¯† |
| TruthfulQA | 40-60% | äº‹å®å‡†ç¡®æ€§ |
| CMMLU/C-Eval | 50-70% | ä¸­æ–‡ç»¼åˆèƒ½åŠ› |

**å¯¹æ¯”åŸºå‡†**ï¼š
- å•æ•™å¸ˆè’¸é¦ï¼šé€šå¸¸æ¯”åŸå§‹å­¦ç”Ÿæ¨¡å‹æå‡ 5-10%
- å¤šæ•™å¸ˆè’¸é¦ï¼šé¢å¤–æå‡ 2-5%
- ä¸‰é˜¶æ®µè·¯ç”±ï¼šStage 1 â†’ Stage 3 ç´¯è®¡æå‡ 3-8%

---

## ğŸ› ï¸ æ•…éšœæ’é™¤

### é—®é¢˜ 1: OOMï¼ˆå†…å­˜æº¢å‡ºï¼‰

```bash
# è§£å†³æ–¹æ¡ˆ A: é™ä½ batch size
BATCH_SIZE=1
GRAD_ACCUM=32  # ä¿æŒæœ‰æ•ˆ batch ä¸å˜

# è§£å†³æ–¹æ¡ˆ B: å¯ç”¨æ›´æ¿€è¿›çš„ä¼˜åŒ–
GRADIENT_CHECKPOINTING=true
USE_BF16=true  # æ¯” FP16 æ›´çœå†…å­˜
torch.backends.cuda.matmul.allow_tf32 = true

# è§£å†³æ–¹æ¡ˆ C: ä½¿ç”¨ 8-bit é‡åŒ–
python experiments/train_multi_teacher_kv.py \
    --load_in_8bit true \
    --bnb_4bit_compute_dtype bfloat16 \
    ...
```

### é—®é¢˜ 2: KV Loss ä¸ä¸‹é™

```bash
# æ£€æŸ¥æ¸…å•ï¼š
# 1. éªŒè¯å¯¹é½æ¨¡å—
python -c "
from align.layer_map import LayerMapper
mapper = LayerMapper(teacher_layers=32, student_layers=24, strategy='ratio')
print(mapper.get_mapping())  # åº”è¾“å‡ºåˆç†çš„å±‚æ˜ å°„
"

# 2. æ£€æŸ¥ KV æå–
python -c "
import torch
model = ...  # åŠ è½½æ•™å¸ˆæ¨¡å‹
outputs = model(..., use_cache=True)
print(outputs.past_key_values[0][0].shape)  # åº”ä¸º [batch, heads, seq, dim]
"

# 3. é™ä½å­¦ä¹ ç‡
LEARNING_RATE=1e-5  # ä» 2e-5 é™ä½

# 4. å¢åŠ  warmup
WARMUP_RATIO=0.2  # ä» 0.1 å¢åŠ 
```

### é—®é¢˜ 3: è·¯ç”±æƒé‡åç¼©

```bash
# ç—‡çŠ¶ï¼šæ‰€æœ‰æƒé‡é›†ä¸­åœ¨å•ä¸€æ•™å¸ˆï¼ˆå¦‚ [0.95, 0.05]ï¼‰

# è§£å†³æ–¹æ¡ˆ A: å¢åŠ ç†µæ­£åˆ™åŒ–
ENTROPY_REG_WEIGHT=0.05  # ä» 0.01 å¢åŠ 

# è§£å†³æ–¹æ¡ˆ B: ä½¿ç”¨æ¸©åº¦é€€ç«
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ ï¼š
# temperature = max(0.5, 1.0 - epoch * 0.1)

# è§£å†³æ–¹æ¡ˆ C: é‡æ–°åˆå§‹åŒ–è·¯ç”±
# ä» Stage 1 é‡æ–°å¼€å§‹ï¼Œä¸ä½¿ç”¨é¢„è®­ç»ƒè·¯ç”±
```

---

## ğŸ“š é¢„æœŸæ—¶é—´ä¸èµ„æº

### å•æ¬¡å®éªŒï¼ˆåŒæ•™å¸ˆï¼Œ15K æ ·æœ¬ï¼‰

| é˜¶æ®µ | æ—¶é—´ï¼ˆ8xA100ï¼‰ | æ˜¾å­˜ï¼ˆæ¯å¡ï¼‰ | æ£€æŸ¥ç‚¹å¤§å° |
|------|----------------|-------------|-----------|
| æ•°æ®å‡†å¤‡ | 30 åˆ†é’Ÿ | 10GB | 5GB |
| KV æå– | 2-4 å°æ—¶ | 60GB | 50-100GB |
| Stage 1 è®­ç»ƒ | 8-12 å°æ—¶ | 70GB | 6GB |
| Stage 2 è®­ç»ƒ | 10-14 å°æ—¶ | 70GB | 6GB |
| Stage 3 è®­ç»ƒ | 12-16 å°æ—¶ | 75GB | 6.5GB |
| è¯„æµ‹ | 1-2 å°æ—¶ | 40GB | - |
| **æ€»è®¡** | **~2-3 å¤©** | **75GB** | **~80GB** |

### å¤šæ¬¡å®éªŒï¼ˆå®Œæ•´æ¶ˆèç ”ç©¶ï¼‰

- 3 ç§æ¨¡å‹ç»„åˆ Ã— 3 ä¸ªè®­ç»ƒé˜¶æ®µ = **9 ä¸ªå®éªŒ**
- æ€»æ—¶é—´ï¼š**~3-4 å‘¨**ï¼ˆå¹¶è¡Œè¿è¡Œï¼‰
- æ€»å­˜å‚¨ï¼š**~1TB**ï¼ˆåŒ…æ‹¬æ•°æ®ã€KVã€æ¨¡å‹ï¼‰

---

## ğŸ“– è®ºæ–‡å¤ç°æ¸…å•

### å¿…åšå®éªŒ
1. âœ… å•å®¶æ—åŒæ•™å¸ˆ + ä¸‰é˜¶æ®µè·¯ç”±ï¼ˆQwenï¼‰
2. âœ… è·¨å®¶æ—åŒæ•™å¸ˆ + ä¸‰é˜¶æ®µè·¯ç”±ï¼ˆQwen+Llamaï¼‰
3. âœ… æ¶ˆèç ”ç©¶ï¼šå›ºå®š vs ç›¸ä¼¼åº¦ vs å¯å­¦ä¹ è·¯ç”±
4. âœ… 7 ä¸ªè¯„æµ‹æ•°æ®é›†çš„å®Œæ•´æµ‹è¯•

### å¯é€‰å®éªŒ
- [ ] å¤šæ•™å¸ˆï¼ˆ3-5 ä¸ªï¼‰æ‰©å±•æ€§åˆ†æ
- [ ] ä¸åŒ KV å‹ç¼©ç­–ç•¥å¯¹æ¯”ï¼ˆfull, right, r-kvï¼‰
- [ ] è·¯ç”±å¯è§†åŒ–ä¸åˆ†æï¼ˆæ•™å¸ˆé€‰æ‹©æ¨¡å¼ï¼‰
- [ ] ä¸­æ–‡æ•°æ®é›†æ¯”ä¾‹æ¶ˆèï¼ˆ10%, 20%, 50%ï¼‰

### é¢„æœŸè´¡çŒ®
1. **æ–¹æ³•åˆ›æ–°**ï¼šé¦–æ¬¡å¤§è§„æ¨¡ï¼ˆ7B+ï¼‰å¤šæ•™å¸ˆ KV è’¸é¦
2. **å·¥ç¨‹è´¡çŒ®**ï¼šå®Œæ•´çš„å¯¹é½æ¡†æ¶ï¼ˆ5 ç§ç­–ç•¥ï¼‰
3. **å®éªŒæ´å¯Ÿ**ï¼š
   - å•å®¶æ— vs è·¨å®¶æ—å¯¹é½éš¾åº¦é‡åŒ–
   - è·¯ç”±ç­–ç•¥çš„å®é™…æ”¶ç›Šåˆ†æ
   - åŒé£æ ¼ï¼ˆCoT+Directï¼‰å¯¹è’¸é¦çš„å½±å“

---

## ğŸ”— ç›¸å…³æ–‡ä»¶

- **SLURM è„šæœ¬**ï¼š
  - `scripts/run_large_scale_multi_teacher.sh`ï¼šå•æ¬¡å®éªŒ
  - `scripts/run_three_stage_routing.sh`ï¼šä¸‰é˜¶æ®µæµç¨‹
  
- **æ ¸å¿ƒä»£ç **ï¼š
  - `data/multi_task_dataset.py`ï¼šæ•°æ®é›†åŠ è½½
  - `scripts/extract_dual_style_kv.py`ï¼šKV æå–
  - `evaluation/multi_task_eval.py`ï¼šè¯„æµ‹æ¡†æ¶
  - `experiments/train_multi_teacher_kv.py`ï¼šè®­ç»ƒä¸»ç¨‹åº
  
- **å¯¹é½æ¨¡å—**ï¼š
  - `align/tokenizer_align.py`
  - `align/time_align.py`
  - `align/layer_map.py`
  - `align/head_dim_adapter.py`
  - `align/rope_scale.py`
  
- **èåˆæ¨¡å—**ï¼š
  - `fuse/fuse_kv.py`ï¼šä¸‰ç§èåˆç­–ç•¥

---

## ğŸ“§ è”ç³»ä¸æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼š
1. æ£€æŸ¥ `logs/` ç›®å½•ä¸‹çš„è®­ç»ƒæ—¥å¿—
2. ä½¿ç”¨ TensorBoard æŸ¥çœ‹è®­ç»ƒæ›²çº¿
3. å‚è€ƒ `MULTI_TEACHER_README.md` ä¸­çš„è¯¦ç»†è¯´æ˜

ç¥å®éªŒé¡ºåˆ©ï¼ğŸ‰
