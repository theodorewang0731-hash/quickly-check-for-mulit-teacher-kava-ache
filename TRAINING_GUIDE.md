# ğŸš€ KAVA åœ°å›¾æŠ•å½±å®æˆ˜è®­ç»ƒæŒ‡å—

## ç¡¬ä»¶é…ç½®
- **GPU**: RTX 4070 (8GB VRAM)
- **æ¨¡å‹ç»„åˆ**: Qwen2.5-1.5B (Teacher) â†’ Qwen2.5-0.5B (Student)
- **ä¼˜åŒ–ç­–ç•¥**: 4-bit é‡åŒ– + æ¢¯åº¦ç´¯ç§¯

---

## ğŸ“‹ æ‰§è¡Œæ­¥éª¤

### Step 1: å®‰è£…ä¾èµ–

```bash
pip install bitsandbytes scipy accelerate datasets transformers
```

**ä¾èµ–è¯´æ˜**:
- `bitsandbytes`: 4-bit é‡åŒ–ï¼ˆæ˜¾å­˜æ•‘æ˜Ÿï¼‰
- `scipy`: æ•°å­¦è®¡ç®—è¾…åŠ©
- `accelerate`: åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- `datasets`: Hugging Face æ•°æ®é›†
- `transformers`: æ¨¡å‹åŠ è½½

---

### Step 2: éªŒè¯ç¯å¢ƒ

```bash
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}, Device: {torch.cuda.get_device_name(0)}')"
```

**é¢„æœŸè¾“å‡º**:
```
CUDA: True, Device: NVIDIA GeForce RTX 4070
```

---

### Step 3: å¯åŠ¨è®­ç»ƒ

```bash
python train_full_dataset.py
```

---

## ğŸ“Š è®­ç»ƒç›‘æ§æŒ‡å—

### æ ¸å¿ƒæŒ‡æ ‡: Cosine Similarity

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¯·é‡ç‚¹å…³æ³¨æ§åˆ¶å°è¾“å‡ºçš„ **CosSim** å€¼ï¼š

| é˜¶æ®µ | æ­¥æ•° | CosSim èŒƒå›´ | çŠ¶æ€ | è¯´æ˜ |
|-----|------|------------|------|------|
| **Phase 1** | 0-50 | 0.20-0.50 | ğŸ”„ Adapting | æ¨¡å‹é€‚åº”ä¸­ï¼Œæ­£å¸¸ç°è±¡ |
| **Phase 2** | 50-100 | 0.50-0.70 | âš ï¸ Learning | å¼€å§‹å­¦ä¹ æ–¹å‘å¯¹é½ |
| **Phase 3** | 100-200 | 0.70-0.90 | ğŸ“ˆ Good | æ˜¾è‘—è¿›æ­¥ï¼Œç»§ç»­è®­ç»ƒ |
| **Phase 4** | 200+ | 0.90-0.95 | ğŸ¯ Great | æ¥è¿‘ç›®æ ‡ï¼Œæ•ˆæœè‰¯å¥½ |
| **Target** | - | >0.95 | âœ… Excellent | å®Œç¾å¯¹é½ï¼Œè®­ç»ƒæˆåŠŸï¼ |

### é¢„æœŸè¾“å‡ºç¤ºä¾‹

```
[Step 0000] Loss: 0.8234 | CosSim: 0.1766 ğŸ”„ Adapting
[Step 0050] Loss: 0.4521 | CosSim: 0.5479 âš ï¸ Learning
[Step 0100] Loss: 0.2145 | CosSim: 0.7855 ğŸ“ˆ Good
[Step 0150] Loss: 0.1023 | CosSim: 0.8977 ğŸ“ˆ Good
[Step 0200] Loss: 0.0432 | CosSim: 0.9568 âœ… Excellent
```

---

## âš™ï¸ é…ç½®è¯´æ˜

### é»˜è®¤é…ç½®ï¼ˆé€‚é… 8GB VRAMï¼‰

```python
CONFIG = {
    "batch_size": 2,                      # å•æ‰¹æ¬¡æ ·æœ¬æ•°
    "gradient_accumulation_steps": 16,    # æ¢¯åº¦ç´¯ç§¯ï¼ˆç­‰æ•ˆ Batch=32ï¼‰
    "max_length": 512,                    # åºåˆ—æœ€å¤§é•¿åº¦
    "lr_projector": 1e-3,                 # Projector å­¦ä¹ ç‡ï¼ˆä»å¤´å­¦ï¼‰
    "lr_student": 5e-5,                   # Student å­¦ä¹ ç‡ï¼ˆå¾®è°ƒï¼‰
    "save_steps": 200,                    # æ¯ 200 æ­¥ä¿å­˜æ£€æŸ¥ç‚¹
}
```

### æ˜¾å­˜ç´§æ€¥é…ç½®ï¼ˆå¦‚é‡ OOMï¼‰

å¦‚æœå¯åŠ¨æ—¶æŠ¥ `CUDA out of memory`ï¼Œä¿®æ”¹é…ç½®ï¼š

```python
"batch_size": 1,                      # é™è‡³ 1
"gradient_accumulation_steps": 32,    # å¢è‡³ 32ï¼ˆä¿æŒç­‰æ•ˆ Batch=32ï¼‰
"max_length": 384,                    # ç¼©çŸ­åºåˆ—ï¼ˆå¯é€‰ï¼‰
```

---

## ğŸ¯ æˆåŠŸæ ‡å¿—

### 1. è®­ç»ƒå®Œæˆæ ‡å¿—

```
âœ… Training Complete!
ğŸ’¾ Final Projector saved: final_projector.pth
ğŸ’¾ Final Student saved: final_student/
```

### 2. å…³é”®æ–‡ä»¶

- `final_projector.pth`: è®­ç»ƒå¥½çš„å¼¹æ€§ç“¶é¢ˆï¼ˆElastic Bottleneckï¼‰
- `final_student/`: è’¸é¦åçš„å­¦ç”Ÿæ¨¡å‹
- `checkpoints/proj_step_*.pth`: ä¸­é—´æ£€æŸ¥ç‚¹

### 3. éªŒè¯æ ‡å‡†

æœ€ç»ˆ CosSim åº”æ»¡è¶³ï¼š
- **ä¼˜ç§€**: CosSim â‰¥ 0.95
- **è‰¯å¥½**: CosSim â‰¥ 0.90
- **åŠæ ¼**: CosSim â‰¥ 0.80

---

## ğŸ” å¸¸è§é—®é¢˜æ’æŸ¥

### Q1: æ˜¾å­˜æº¢å‡º (OOM)

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate 1.23 GiB
```

**è§£å†³æ–¹æ¡ˆ**:
1. é™ä½ `batch_size` åˆ° 1
2. å‡å°‘ `max_length` åˆ° 384 æˆ– 256
3. æ£€æŸ¥åå°è¿›ç¨‹ï¼ˆå…³é—­ä¸å¿…è¦çš„ GPU å ç”¨ï¼‰

### Q2: CosSim ä¸ä¸Šå‡

**ç—‡çŠ¶**:
- 200 æ­¥å CosSim ä» <0.50
- Loss ä¸‹é™ä½† CosSim åœæ»

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡è¿‡ä½ï¼šå°è¯• `lr_projector=2e-3`
2. æ•°æ®è´¨é‡é—®é¢˜ï¼šæ£€æŸ¥ GSM8K æ˜¯å¦æ­£ç¡®åŠ è½½
3. æ¨¡å‹ç»´åº¦ä¸åŒ¹é…ï¼šç¡®è®¤ Teacher/Student é…ç½®æ­£ç¡®

**è°ƒè¯•å‘½ä»¤**:
```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ è°ƒè¯•è¾“å‡º
print(f"Teacher KV shape: {t_kv.shape}")
print(f"Student KV shape: {s_kv.shape}")
print(f"Projected shape: {t_proj.shape}")
```

### Q3: Loss éœ‡è¡

**ç—‡çŠ¶**:
- Loss ä¸Šä¸‹æ³¢åŠ¨å‰§çƒˆ
- CosSim æ—¶é«˜æ—¶ä½

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°åˆ° 32
2. é™ä½å­¦ä¹ ç‡ï¼š`lr_projector=5e-4`
3. å¯ç”¨æ›´å¼ºçš„æ¢¯åº¦è£å‰ªï¼š`max_grad_norm=0.5`

### Q4: æ•°æ®é›†ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**:
```
ConnectionError: Couldn't reach https://huggingface.co/datasets/gsm8k
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ–¹æ³• 1: è®¾ç½® HF é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com

# æ–¹æ³• 2: æ‰‹åŠ¨ä¸‹è½½æ•°æ®é›†
git clone https://huggingface.co/datasets/gsm8k
# ç„¶åä¿®æ”¹ä»£ç ï¼šload_dataset("./gsm8k", ...)
```

---

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

### è®­ç»ƒé€Ÿåº¦

- **RTX 4070 (8GB)**: ~2-3 it/s
- **æ¯ Epoch**: ~3-4 å°æ—¶ï¼ˆ7473 æ ·æœ¬ / 2 batch_sizeï¼‰
- **æ¨èæ­¥æ•°**: 500-1000 æ­¥ï¼ˆè¶³å¤Ÿçœ‹åˆ°æ•ˆæœï¼‰

### æ˜¾å­˜å ç”¨

| ç»„ä»¶ | æ˜¾å­˜å ç”¨ | è¯´æ˜ |
|-----|---------|------|
| Teacher (4-bit) | ~1.5GB | é‡åŒ–å |
| Student (bf16) | ~1.2GB | åŠç²¾åº¦ |
| Projector | ~0.3GB | MLP å‚æ•° |
| æ¿€æ´»å€¼ (Batch=2) | ~3.5GB | å‰å‘+åå‘ |
| **Total** | ~6.5GB | é¢„ç•™ 1.5GB ä½™é‡ |

---

## ğŸ“ ç†è®ºå›é¡¾

### ä¸ºä»€ä¹ˆåœ°å›¾æŠ•å½±æœ‰æ•ˆï¼Ÿ

**ä¼ ç»Ÿ MSE**:
```
Teacher KV: [100, 100]  (é«˜ç½®ä¿¡åº¦)
Student KV: [1, 1]      (ä½ç½®ä¿¡åº¦)
MSE Loss = 76.57        âŒ è¯¯åˆ¤ä¸ºé”™è¯¯
```

**Mercator Loss**:
```
Teacher Direction: [0.707, 0.707]
Student Direction: [0.707, 0.707]
Cosine Similarity = 1.0  âœ… è¯†åˆ«ç›¸åŒè¯­ä¹‰
Mercator Loss = 0.0      âœ… å®Œç¾å¯¹é½
```

**æ ¸å¿ƒæ´å¯Ÿ**:
- RoPE æ¨¡å‹ï¼šæ–¹å‘ = è¯­ä¹‰ï¼Œæ¨¡é•¿ = ç½®ä¿¡åº¦
- è’¸é¦ç›®æ ‡ï¼šå­¦ä¹ è¯­ä¹‰æ–¹å‘ï¼Œè€Œéæ•°å€¼å¤§å°
- åœ°å›¾æŠ•å½±ï¼šå½’ä¸€åŒ–åˆ°å•ä½çƒï¼Œåªæ¯”è¾ƒæ–¹å‘

---

## ğŸ”§ é«˜çº§è°ƒå‚

### å®éªŒç»„åˆæ¨è

| å®éªŒå | mlp_ratio | alpha | beta | é€‚ç”¨åœºæ™¯ |
|-------|-----------|-------|------|---------|
| **Pure Direction** | 1.0 | 1.0 | 0.0 | çº¯æ–¹å‘å¯¹é½ |
| **Weak Constraint** | 1.0 | 1.0 | 0.01 | æ¨èï¼ˆé˜²å¡Œç¼©ï¼‰ |
| **Strong Constraint** | 1.0 | 1.0 | 0.1 | æ•°å€¼å·®å¼‚å°æ—¶ |
| **High Capacity** | 2.0 | 1.0 | 0.01 | å¤æ‚ä»»åŠ¡ |
| **Low Capacity** | 0.5 | 1.0 | 0.01 | æ˜¾å­˜å—é™ |

### è°ƒå‚ä¼˜å…ˆçº§

1. **é¦–å…ˆè°ƒæ•´**: `batch_size` + `gradient_accumulation_steps`ï¼ˆæ˜¾å­˜é€‚é…ï¼‰
2. **å…¶æ¬¡è°ƒæ•´**: `lr_projector`ï¼ˆæ”¶æ•›é€Ÿåº¦ï¼‰
3. **æœ€åè°ƒæ•´**: `beta`ï¼ˆä»…å½“æ•°å€¼å¼‚å¸¸æ—¶ï¼‰

---

## ğŸ“ å®éªŒè®°å½•æ¨¡æ¿

```yaml
experiment:
  name: "KAVA-Mercator-1.5B-to-0.5B"
  date: "2025-11-26"
  
hardware:
  gpu: "RTX 4070 8GB"
  batch_size: 2
  grad_accum: 16
  
models:
  teacher: "Qwen/Qwen2.5-1.5B-Instruct"
  student: "Qwen/Qwen2.5-0.5B"
  
config:
  mlp_ratio: 1.0
  dropout: 0.1
  alpha: 1.0
  beta: 0.01
  lr_projector: 1e-3
  lr_student: 5e-5
  
results:
  final_cos_sim: 0.XXX
  final_loss: 0.XXX
  training_time: "X hours"
  
notes: |
  åœ¨æ­¤è®°å½•è§‚å¯Ÿåˆ°çš„ç°è±¡ã€é‡åˆ°çš„é—®é¢˜ã€è§£å†³æ–¹æ¡ˆç­‰ã€‚
```

---

## ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. âœ… **è¿è¡Œè®­ç»ƒ**: `python train_full_dataset.py`
2. â­ï¸ **ç›‘æ§ CosSim**: æ¯ 50 æ­¥æŸ¥çœ‹è¿›åº¦
3. â­ï¸ **ç­‰å¾…å®Œæˆ**: é¢„è®¡ 3-4 å°æ—¶ï¼ˆæˆ–æå‰åœæ­¢ï¼‰
4. â­ï¸ **è¯„ä¼°æ•ˆæœ**: åŠ è½½ `final_student` æµ‹è¯• GSM8K
5. â­ï¸ **å¯¹æ¯”åŸºçº¿**: MSE vs Mercator æ€§èƒ½å·®å¼‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

- **Elastic Bottleneck**: `experiments/kv_dimension_projector.py`
- **Map Projection**: `src/losses.py`
- **éªŒè¯æµ‹è¯•**: `tests/verify_map_projection.py`
- **å®Œæ•´æŒ‡å—**: `docs/MAP_PROJECTION_GUIDE.md`

---

**å‡†å¤‡å¥½äº†å—ï¼Ÿå¼€å§‹ä½ çš„ KAVA ä¹‹æ—…å§ï¼** ğŸ‰

```bash
python train_full_dataset.py
```

ç¥è®­ç»ƒé¡ºåˆ©ï¼ŒCosSim æ—©æ—¥çªç ´ 0.95ï¼ ğŸš€
