# KAVA å¯¹é½æ–¹æ³•å®Œæ•´è¯´æ˜

## ğŸ“‹ ç›®å½•
1. [å¯¹é½æ–¹æ³•æ¦‚è§ˆ](#å¯¹é½æ–¹æ³•æ¦‚è§ˆ)
2. [æ ¸å¿ƒå¯¹é½æ–¹æ³•](#æ ¸å¿ƒå¯¹é½æ–¹æ³•)
3. [ç»´åº¦å¯¹é½æ–¹æ³•](#ç»´åº¦å¯¹é½æ–¹æ³•)
4. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
5. [å®Œæ•´æµç¨‹](#å®Œæ•´æµç¨‹)

---

## å¯¹é½æ–¹æ³•æ¦‚è§ˆ

### å½“å‰ä½¿ç”¨çš„å¯¹é½æ–¹æ³•

| å¯¹é½ç±»å‹ | æ–¹æ³•åç§° | ç›®çš„ | å®ç°ä½ç½® |
|---------|---------|------|---------|
| **è¯­ä¹‰å¯¹é½** | Mercator Projection Loss | å¯¹é½è¯­ä¹‰æ–¹å‘ï¼ˆä¸»è¦ï¼‰ | `src/losses.py` |
| **æ··åˆå¯¹é½** | Hybrid Loss | Mercator + MSE æ··åˆ | `src/losses.py` |
| **ç»´åº¦å¯¹é½** | Elastic Bottleneck Projector | Teacherç»´åº¦ â†’ Studentç»´åº¦ | `experiments/kv_dimension_projector.py` |
| **è·¨å±‚èšåˆ** | Cross-Layer Aggregation | èšåˆæ‰€æœ‰å±‚çš„KV | `src/dynamic_kv_extractor.py` |

---

## æ ¸å¿ƒå¯¹é½æ–¹æ³•

### 1. Mercator Projection Lossï¼ˆä¸»è¦æ–¹æ³•ï¼‰â­

#### ğŸ“– æ ¸å¿ƒæ€æƒ³
**å¯¹é½è¯­ä¹‰æ–¹å‘è€Œéæ•°å€¼å¤§å°**

- **æ–¹å‘** = è¯­ä¹‰å«ä¹‰ï¼ˆå‘é‡æŒ‡å‘å“ªé‡Œï¼‰
- **å¹…åº¦** = ç½®ä¿¡åº¦ï¼ˆå‘é‡æœ‰å¤šé•¿ï¼‰

å¯¹äº RoPE-based æ¨¡å‹ï¼ˆQwen/Llamaï¼‰ï¼Œæ—‹è½¬ä¸€è‡´æ€§ï¼ˆæ–¹å‘ï¼‰æ¯”æ•°å€¼è¿‘ä¼¼ï¼ˆå¹…åº¦ï¼‰æ›´é‡è¦ã€‚

#### ğŸ“ æ•°å­¦å…¬å¼

```python
# 1. æŠ•å½±åˆ°å•ä½çƒé¢ï¼ˆå½’ä¸€åŒ–ï¼‰
s_norm = student_kv / ||student_kv||    # [B, T, D]
t_norm = teacher_kv / ||teacher_kv||    # [B, T, D]

# 2. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆæ–¹å‘ä¸€è‡´æ€§ï¼‰
cos_sim = mean(s_norm Â· t_norm)         # æ ‡é‡ï¼ŒèŒƒå›´ [-1, 1]

# 3. Mercator Loss
direction_loss = 1 - cos_sim             # cos_sim=1æ—¶loss=0ï¼ˆå®Œç¾ï¼‰

# 4. å¯é€‰ï¼šå¼±å¹…åº¦çº¦æŸï¼ˆé˜²æ­¢åç¼©ï¼‰
magnitude_loss = MSE(log(||s||), log(||t||))

# 5. æ€»æŸå¤±
total_loss = Î± Ã— direction_loss + Î² Ã— magnitude_loss
```

**æ¨èå‚æ•°**ï¼š
- `Î± = 1.0` ï¼ˆæ–¹å‘æŸå¤±æƒé‡ï¼‰
- `Î² = 0.0` æˆ– `0.01` ï¼ˆå¹…åº¦çº¦æŸï¼Œå¯é€‰ï¼‰

#### ğŸ’¡ ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿ

**åœºæ™¯å¯¹æ¯”ï¼š**

| Teacher | Student | MSE Loss | Mercator Loss |
|---------|---------|----------|---------------|
| 100Ã—[0.707, 0.707] | 1Ã—[0.707, 0.707] | å¾ˆå¤§ âŒ | 0.0 âœ… |
| [1.0, 0.0] | [0.0, 1.0] | 2.0 âŒ | 2.0 âŒ |
| [1.0, 0.0] | [1.0, 0.0] | 0.0 âœ… | 0.0 âœ… |

**å…³é”®ä¼˜åŠ¿ï¼š**
- âœ… è¯†åˆ«è¯­ä¹‰å¯¹é½ï¼ˆå³ä½¿å¹…åº¦ä¸åŒï¼‰
- âœ… ä¸æƒ©ç½šç½®ä¿¡åº¦å·®å¼‚
- âœ… ä¸“æ³¨äºæ–¹å‘ä¸€è‡´æ€§

#### ğŸ”§ å®ç°ä»£ç 

```python
class MercatorKVLoss(nn.Module):
    def __init__(self, alpha=1.0, beta=0.0, epsilon=1e-8):
        super().__init__()
        self.alpha = alpha  # æ–¹å‘æŸå¤±æƒé‡
        self.beta = beta    # å¹…åº¦æŸå¤±æƒé‡ï¼ˆå¯é€‰ï¼‰
        self.epsilon = epsilon
    
    def forward(self, student_kv, teacher_kv):
        """
        Args:
            student_kv: [Batch, Seq, Dim] - Studentçš„KVè¡¨ç¤º
            teacher_kv: [Batch, Seq, Dim] - Teacherçš„KVè¡¨ç¤º
        
        Returns:
            total_loss: æ ‡é‡æŸå¤±
            metrics: è¯¦ç»†æŒ‡æ ‡å­—å…¸
        """
        # Step 1: MercatoræŠ•å½±ï¼ˆæ–¹å‘å¯¹é½ï¼‰
        s_norm = F.normalize(student_kv, p=2, dim=-1)
        t_norm = F.normalize(teacher_kv, p=2, dim=-1)
        
        # Step 2: è®¡ç®—æ–¹å‘ä¸€è‡´æ€§
        cos_sim = torch.sum(s_norm * t_norm, dim=-1).mean()
        direction_loss = 1.0 - cos_sim
        
        # Step 3: å¯é€‰å¹…åº¦çº¦æŸ
        if self.beta > 0:
            s_mag = torch.norm(student_kv, p=2, dim=-1)
            t_mag = torch.norm(teacher_kv, p=2, dim=-1)
            magnitude_loss = F.mse_loss(
                torch.log(s_mag + self.epsilon),
                torch.log(t_mag + self.epsilon)
            )
        else:
            magnitude_loss = 0.0
        
        # Step 4: ç»„åˆæŸå¤±
        total_loss = self.alpha * direction_loss + self.beta * magnitude_loss
        
        # Step 5: æ”¶é›†æŒ‡æ ‡
        metrics = {
            "cos_sim": cos_sim.item(),           # æ ¸å¿ƒæŒ‡æ ‡ï¼šç›®æ ‡ > 0.95
            "dir_loss": direction_loss.item(),
            "mag_loss": magnitude_loss.item() if self.beta > 0 else 0.0,
        }
        
        return total_loss, metrics
```

#### ğŸ“Š è®­ç»ƒç›®æ ‡

| é˜¶æ®µ | CosSim èŒƒå›´ | çŠ¶æ€ |
|------|-------------|------|
| 0-50æ­¥ | 0.20-0.50 | ğŸ”„ é€‚åº”ä¸­ |
| 50-100æ­¥ | 0.50-0.70 | âš ï¸ å­¦ä¹ ä¸­ |
| 100-200æ­¥ | 0.70-0.90 | ğŸ“ˆ è‰¯å¥½ |
| 200+æ­¥ | **>0.90** | âœ… ä¼˜ç§€ â† **ç›®æ ‡** |

---

### 2. Hybrid Lossï¼ˆæ··åˆæ–¹æ³•ï¼‰

#### ğŸ“– æ ¸å¿ƒæ€æƒ³
æ¸è¿›å¼ä» MSE è¿‡æ¸¡åˆ° Mercator

é€‚ç”¨åœºæ™¯ï¼š
- è®­ç»ƒåˆæœŸéœ€è¦æ›´å¼ºçš„æ•°å€¼çº¦æŸ
- é€æ­¥è½¬å‘æ–¹å‘å¯¹é½
- å¹³è¡¡ä¼ ç»ŸæŸå¤±å’Œæ–°æ–¹æ³•

#### ğŸ“ æ•°å­¦å…¬å¼

```python
# Mercatoråˆ†é‡
merc_loss = MercatorLoss(student, teacher)

# MSEåˆ†é‡
mse_loss = MSE(student, teacher)

# æ··åˆ
total_loss = w_merc Ã— merc_loss + w_mse Ã— mse_loss
```

**æ¨èæƒé‡ï¼š**
- `w_merc = 0.8`ï¼ˆMercatorä¸»å¯¼ï¼‰
- `w_mse = 0.2`ï¼ˆMSEè¾…åŠ©ï¼‰

#### ğŸ”§ å®ç°ä»£ç 

```python
class HybridKVLoss(nn.Module):
    def __init__(self, mercator_weight=0.8, mse_weight=0.2, beta=0.01):
        super().__init__()
        self.mercator_weight = mercator_weight
        self.mse_weight = mse_weight
        
        self.mercator_loss = MercatorKVLoss(alpha=1.0, beta=beta)
        self.mse_loss = nn.MSELoss()
    
    def forward(self, student_kv, teacher_kv):
        # Mercatoréƒ¨åˆ†
        merc_loss, merc_metrics = self.mercator_loss(student_kv, teacher_kv)
        
        # MSEéƒ¨åˆ†
        mse = self.mse_loss(student_kv, teacher_kv)
        
        # ç»„åˆ
        total_loss = (self.mercator_weight * merc_loss + 
                      self.mse_weight * mse)
        
        return total_loss, metrics
```

---

## ç»´åº¦å¯¹é½æ–¹æ³•

### 3. Elastic Bottleneck Projector â­

#### ğŸ“– æ ¸å¿ƒæ€æƒ³
**å°†Teacherçš„é«˜ç»´KVæŠ•å½±åˆ°Studentçš„ä½ç»´ç©ºé—´**

é—®é¢˜ï¼š
- Teacher: Qwen-1.5B (7168ç»´)
- Student: Qwen-0.5B (3072ç»´)
- æ— æ³•ç›´æ¥å¯¹é½ï¼

è§£å†³ï¼šå¯å­¦ä¹ çš„ç»´åº¦æŠ•å½±ç½‘ç»œ

#### ğŸ—ï¸ æ¶æ„è®¾è®¡

```python
Input: Teacher KV [B, T, 7168]
    â†“
LayerNorm(7168)          # ç¨³å®šæ¢¯åº¦
    â†“
Linear(7168 â†’ 7168)      # ç‰¹å¾å˜æ¢
    â†“
SiLU()                   # éçº¿æ€§æ¿€æ´»
    â†“
Dropout(0.1)             # æ­£åˆ™åŒ–
    â†“
Linear(7168 â†’ 3072)      # é™ç»´æŠ•å½±
    â†“
Output: Aligned KV [B, T, 3072]
```

**å…³é”®ç»„ä»¶ï¼š**
1. **Pre-LayerNorm**: ç¨³å®šæ•°å€¼ï¼Œè·¨æ¨¡å‹å°ºåº¦é€šç”¨
2. **Elastic MLP**: å¯è°ƒèŠ‚éšè—å±‚å®½åº¦ï¼ˆmlp_ratioï¼‰
3. **Non-linear**: SiLUæ¿€æ´»æ•è·å¤æ‚ç‰¹å¾
4. **Separate K/V**: Keyså’ŒValuesç‹¬ç«‹æŠ•å½±

#### ğŸ“ æ•°å­¦å…¬å¼

```python
# K æŠ•å½±
K_aligned = Linear2(Dropout(SiLU(Linear1(LayerNorm(K_teacher)))))
          : [B, T, d_t] â†’ [B, T, d_s]

# V æŠ•å½±ï¼ˆç‹¬ç«‹ç½‘ç»œï¼‰
V_aligned = Linear2(Dropout(SiLU(Linear1(LayerNorm(V_teacher)))))
          : [B, T, d_t] â†’ [B, T, d_s]
```

**ç»´åº¦å˜åŒ–ï¼š**
```
Teacher: 7168ç»´ â†’ Hidden: 7168ç»´ â†’ Student: 3072ç»´
         (d_t)     (d_t Ã— mlp_ratio)    (d_s)
```

#### ğŸ”§ å®ç°ä»£ç 

```python
class KVDimensionProjector(nn.Module):
    def __init__(
        self,
        teacher_configs: Dict[str, Dict[str, int]],
        student_d_model: int,
        mlp_ratio: float = 1.0,
        dropout: float = 0.1,
    ):
        super().__init__()
        
        self.projectors = nn.ModuleDict()
        
        for teacher_name, config in teacher_configs.items():
            teacher_d_model = config["d_model"]
            hidden_dim = int(teacher_d_model * mlp_ratio)
            
            # K æŠ•å½±å™¨
            adapter_K = nn.Sequential(
                nn.LayerNorm(teacher_d_model),     # ç¨³å®šæ€§
                nn.Linear(teacher_d_model, hidden_dim),
                nn.SiLU(),                          # éçº¿æ€§
                nn.Dropout(dropout),                # æ­£åˆ™åŒ–
                nn.Linear(hidden_dim, student_d_model)
            )
            
            # V æŠ•å½±å™¨ï¼ˆç‹¬ç«‹ï¼‰
            adapter_V = nn.Sequential(
                nn.LayerNorm(teacher_d_model),
                nn.Linear(teacher_d_model, hidden_dim),
                nn.SiLU(),
                nn.Dropout(dropout),
                nn.Linear(hidden_dim, student_d_model)
            )
            
            self.projectors[teacher_name] = nn.ModuleDict({
                "K": adapter_K,
                "V": adapter_V
            })
    
    def project_teacher_kv(self, teacher_name, teacher_K, teacher_V):
        """
        æŠ•å½±Teacher KVåˆ°Studentç»´åº¦
        
        Args:
            teacher_K: [B, T, d_teacher] = [B, T, 7168]
            teacher_V: [B, T, d_teacher] = [B, T, 7168]
        
        Returns:
            K_aligned: [B, T, d_student] = [B, T, 3072]
            V_aligned: [B, T, d_student] = [B, T, 3072]
        """
        proj_K = self.projectors[teacher_name]["K"]
        proj_V = self.projectors[teacher_name]["V"]
        
        K_aligned = proj_K(teacher_K)
        V_aligned = proj_V(teacher_V)
        
        return K_aligned, V_aligned
```

#### ğŸ¯ å‚æ•°é…ç½®

| æ¨¡å‹è§„æ¨¡ | mlp_ratio | è¯´æ˜ |
|---------|-----------|------|
| <7B | 0.5-1.0 | å‹ç¼©ç“¶é¢ˆï¼Œå‡å°‘å‚æ•° |
| 7B-30B | 1.0 | ç­‰å®½å˜æ¢ï¼Œå¹³è¡¡æ€§èƒ½ |
| 30B-70B+ | 2.0 | æ‰©å±•ç‰¹å¾ï¼Œæ•è·å¤æ‚æ€§ |

**å½“å‰é…ç½®ï¼ˆQwen 1.5B â†’ 0.5Bï¼‰ï¼š**
- `mlp_ratio = 1.0`
- `dropout = 0.1`
- å‚æ•°é‡: **147M**ï¼ˆä¸¤ä¸ªæŠ•å½±å™¨ï¼‰

---

### 4. Cross-Layer Aggregationï¼ˆè·¨å±‚èšåˆï¼‰

#### ğŸ“– æ ¸å¿ƒæ€æƒ³
**èšåˆæ‰€æœ‰å±‚çš„KVè€Œéåªç”¨æœ€åä¸€å±‚**

é—®é¢˜ï¼š
- é‡åŒ–æ¨¡å‹å•å±‚ç»´åº¦å°ï¼ˆ256ç»´ï¼‰
- é…ç½®ç»´åº¦å¤§ï¼ˆ1536ç»´ï¼‰
- ç»´åº¦ä¸åŒ¹é…ï¼

è§£å†³ï¼šæ‹¼æ¥æ‰€æœ‰28å±‚çš„KV

#### ğŸ“ æ•°å­¦å…¬å¼

```python
# ä¼ ç»Ÿæ–¹æ³•ï¼ˆå•å±‚ï¼‰
k_last, v_last = past_key_values[-1]  # åªå–æœ€åä¸€å±‚
k_flat = flatten(k_last)               # [B, T, 256]
# é—®é¢˜ï¼šç»´åº¦å¤ªå° 256 â‰  1536

# è·¨å±‚èšåˆï¼ˆå…¨å±‚ï¼‰
all_kvs = []
for layer_kv in past_key_values:      # éå†æ‰€æœ‰28å±‚
    k, v = layer_kv
    k_flat = flatten(k)                # [B, T, 256]
    all_kvs.append(k_flat)

k_combined = concat(all_kvs, dim=-1)  # [B, T, 28Ã—256] = [B, T, 7168]
# è§£å†³ï¼š28å±‚ Ã— 256ç»´/å±‚ = 7168ç»´ âœ“
```

#### ğŸ” ç»´åº¦åˆ†æ

**Teacher (Qwen-1.5B 4-bit):**
```
é…ç½®ç»´åº¦: 1536
å±‚æ•°: 28
æ¯å±‚æ³¨æ„åŠ›å¤´: 2ï¼ˆé‡åŒ–åï¼‰
æ¯å¤´ç»´åº¦: 128
å•å±‚ç»´åº¦: 2 Ã— 128 = 256
æ€»ç»´åº¦: 28 Ã— 256 = 7168 â† å®é™…ä½¿ç”¨
```

**Student (Qwen-0.5B):**
```
é…ç½®ç»´åº¦: 896
å±‚æ•°: 24
æ¯å±‚æ³¨æ„åŠ›å¤´: 2
æ¯å¤´ç»´åº¦: 128  
å•å±‚ç»´åº¦: 2 Ã— 128 = 128
æ€»ç»´åº¦: 24 Ã— 128 = 3072 â† å®é™…ä½¿ç”¨
```

#### ğŸ”§ å®ç°ä»£ç 

```python
class DynamicKVExtractor:
    def __init__(
        self,
        aggregation_method: str = "concat",  # concat / mean / weighted
        use_all_layers: bool = True,
    ):
        self.aggregation_method = aggregation_method
        self.use_all_layers = use_all_layers
    
    def extract_kv(self, past_key_values):
        """
        æå–å¹¶èšåˆKV Cache
        
        Args:
            past_key_values: Tuple of (key, value) for each layer
                key: [B, H, T, D_h] for each layer
        
        Returns:
            kv_flat: [B, T, total_dim]
        """
        if self.aggregation_method == "concat":
            return self._extract_concat(past_key_values)
    
    def _extract_concat(self, past_key_values):
        """æ‹¼æ¥èšåˆæ–¹æ³•"""
        all_kvs = []
        
        for layer_kv in past_key_values:  # éå†æ‰€æœ‰å±‚
            k, v = layer_kv
            # k shape: [B, H, T, D_h]
            
            # å±•å¹³å•å±‚ï¼š[B, H, T, D_h] â†’ [B, T, HÃ—D_h]
            B, H, T, D_h = k.shape
            k_flat = k.permute(0, 2, 1, 3).contiguous().view(B, T, H * D_h)
            all_kvs.append(k_flat)
        
        # æ‹¼æ¥æ‰€æœ‰å±‚ï¼š[B, T, num_layers Ã— H Ã— D_h]
        kv_combined = torch.cat(all_kvs, dim=-1)
        
        return kv_combined
```

#### ğŸ¯ èšåˆç­–ç•¥å¯¹æ¯”

| æ–¹æ³• | è¾“å‡ºç»´åº¦ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|-----|---------|------|------|
| **concat** | 28Ã—256=7168 | ä¿ç•™æ‰€æœ‰ä¿¡æ¯ | ç»´åº¦å¤§ |
| mean | 256 | ç»´åº¦å° | ä¿¡æ¯æŸå¤± |
| weighted | 256 | å¯å­¦ä¹ æƒé‡ | éœ€è¦è°ƒä¼˜ |

**å½“å‰ä½¿ç”¨ï¼šconcat**ï¼ˆä¿ç•™å®Œæ•´ä¿¡æ¯ï¼‰

---

## å®ç°ç»†èŠ‚

### ğŸ”„ å®Œæ•´å¯¹é½æµç¨‹

```python
# è®­ç»ƒå¾ªç¯ä¸­çš„å¯¹é½æµç¨‹

for batch in dataloader:
    # ===== Step 1: å‰å‘ä¼ æ’­è·å–KV Cache =====
    with torch.no_grad():
        t_out = teacher(input_ids, attention_mask, use_cache=True)
        # t_out.past_key_values: Tuple[Tuple[Tensor, Tensor], ...]
        #   æ¯ä¸ªå…ƒç´ : (key, value) for one layer
        #   key shape: [B, H, T, D_h]
    
    s_out = student(input_ids, attention_mask, use_cache=True)
    # åŒä¸Š
    
    # ===== Step 2: è·¨å±‚èšåˆ (Cross-Layer Aggregation) =====
    t_kv = kv_extractor.extract_kv(
        t_out.past_key_values,
        model_name="teacher"
    )
    # Output: [B, T, 7168] â† 28å±‚èšåˆ
    
    s_kv = kv_extractor.extract_kv(
        s_out.past_key_values,
        model_name="student"
    )
    # Output: [B, T, 3072] â† 24å±‚èšåˆ
    
    # ===== Step 3: æ•°æ®ç±»å‹è½¬æ¢ =====
    t_kv = t_kv.to(torch.bfloat16)  # ç»Ÿä¸€ç²¾åº¦
    s_kv = s_kv.to(torch.bfloat16)
    
    # ===== Step 4: ç»´åº¦å¯¹é½ (Elastic Bottleneck) =====
    t_proj, _ = projector.project_teacher_kv("teacher", t_kv, t_kv)
    # Input:  [B, T, 7168]
    # Output: [B, T, 3072] â† ä¸Studentç»´åº¦åŒ¹é…
    
    # ===== Step 5: è¯­ä¹‰å¯¹é½ (Mercator Loss) =====
    loss, metrics = loss_fn(s_kv, t_proj)
    # s_kv:   [B, T, 3072] Student KV
    # t_proj: [B, T, 3072] Teacher KV (å¯¹é½å)
    # 
    # å†…éƒ¨è®¡ç®—ï¼š
    # 1. å½’ä¸€åŒ–åˆ°å•ä½çƒé¢
    # 2. è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    # 3. direction_loss = 1 - cos_sim
    
    # ===== Step 6: åå‘ä¼ æ’­ =====
    loss.backward()
    optimizer.step()
    
    # ===== ç›‘æ§æŒ‡æ ‡ =====
    print(f"Loss: {loss.item():.4f}")
    print(f"CosSim: {metrics['cos_sim']:.4f}")  # ç›®æ ‡ > 0.90
```

### ğŸ“Š ç»´åº¦å˜åŒ–è¿½è¸ª

```
Teacher (Qwen-1.5B 4-bit):
  Model Output â†’ [B, 28_layers, H=2, T, D_h=128]
      â†“ Cross-Layer Aggregation
  Flattened â†’ [B, T, 28Ã—2Ã—128] = [B, T, 7168]
      â†“ Type Conversion
  BF16 â†’ [B, T, 7168]
      â†“ Elastic Bottleneck Projector
  Aligned â†’ [B, T, 3072]
      â†“ Mercator Loss
  Direction Loss â† Compare with Student

Student (Qwen-0.5B):
  Model Output â†’ [B, 24_layers, H=2, T, D_h=128]
      â†“ Cross-Layer Aggregation
  Flattened â†’ [B, T, 24Ã—2Ã—128] = [B, T, 3072]
      â†“ Type Conversion
  BF16 â†’ [B, T, 3072]
      â†“ (No projection needed)
  Ready â†’ [B, T, 3072]
      â†“ Mercator Loss
  Direction Loss â† Compare with Teacher
```

---

## å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     KAVAå¯¹é½å®Œæ•´æµç¨‹                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Teacher       â”‚         â”‚    Student      â”‚
â”‚  Qwen-1.5B      â”‚         â”‚   Qwen-0.5B     â”‚
â”‚   (4-bit)       â”‚         â”‚   (bfloat16)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â”‚ Forward Pass              â”‚ Forward Pass
         â”‚ use_cache=True            â”‚ use_cache=True
         â†“                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ past_key_values â”‚         â”‚ past_key_values â”‚
â”‚ 28 layers       â”‚         â”‚ 24 layers       â”‚
â”‚ [B,H,T,D_h]     â”‚         â”‚ [B,H,T,D_h]     â”‚
â”‚ per layer       â”‚         â”‚ per layer       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â””â†’â”‚  Cross-Layer         â”‚â†â”€â”˜
           â”‚  Aggregation         â”‚
           â”‚  (concat all layers) â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Flattened KV Cache        â”‚
         â”‚  Teacher: [B, T, 7168]     â”‚
         â”‚  Student: [B, T, 3072]     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ Type Conversion
                      â”‚ to BF16
                      â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Unified Precision         â”‚
         â”‚  Both in BF16              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                         â”‚
         â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Teacher KV     â”‚       â”‚   Student KV    â”‚
â”‚  [B, T, 7168]   â”‚       â”‚   [B, T, 3072]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
         â”‚ Elastic                 â”‚ (No projection)
         â”‚ Bottleneck              â”‚
         â”‚ Projector               â”‚
         â†“                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  Aligned KV     â”‚                â”‚
â”‚  [B, T, 3072]   â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
         â”‚                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Mercator Loss  â”‚
         â”‚  (Direction)    â”‚
         â”‚                 â”‚
         â”‚  1. Normalize   â”‚
         â”‚  2. CosSim      â”‚
         â”‚  3. Loss=1-cos  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Backprop &     â”‚
         â”‚  Update:        â”‚
         â”‚  - Student      â”‚
         â”‚  - Projector    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ˆ è®­ç»ƒé…ç½®

### å½“å‰ä½¿ç”¨çš„é…ç½®

```python
# æ¨¡å‹é…ç½®
GLOBAL_CONFIG = {
    # æ¨¡å‹
    'teacher_model_name': 'Qwen/Qwen2.5-1.5B-Instruct',
    'student_model_name': 'Qwen/Qwen2.5-0.5B',
    'teacher_quantization': '4bit',
    
    # æŸå¤±å‡½æ•°ï¼ˆMercatorï¼‰
    'loss_alpha': 1.0,   # æ–¹å‘æŸå¤±æƒé‡
    'loss_beta': 0.01,   # å¹…åº¦æŸå¤±æƒé‡ï¼ˆå¼±çº¦æŸï¼‰
    
    # KVæå–ï¼ˆCross-Layerï¼‰
    'kv_aggregation_method': 'concat',
    'use_all_layers': True,
    
    # ä¼˜åŒ–å™¨
    'learning_rate_student': 5e-5,      # Studentå­¦ä¹ ç‡
    'learning_rate_projector': 1e-3,    # Projectorå­¦ä¹ ç‡ï¼ˆæ›´é«˜ï¼‰
    'weight_decay': 0.01,
    
    # è®­ç»ƒ
    'max_length': 512,
    'batch_size': 2,                     # è‡ªåŠ¨è°ƒæ•´
    'gradient_accumulation_steps': 16,   # è‡ªåŠ¨è°ƒæ•´
    'max_steps': 1000,
}
```

### ç»´åº¦ä¿¡æ¯

```python
# åŠ¨æ€æ£€æµ‹åˆ°çš„å®é™…ç»´åº¦
Teacher: 
  - Config: 1536ç»´
  - Actual: 7168ç»´ (28å±‚ Ã— 256ç»´/å±‚)
  - Layers: 28
  - Heads per layer: 2 (é‡åŒ–å)
  - Head dim: 128

Student:
  - Config: 896ç»´
  - Actual: 3072ç»´ (24å±‚ Ã— 128ç»´/å±‚)
  - Layers: 24
  - Heads per layer: 2
  - Head dim: 128

Projector:
  - Input: 7168ç»´
  - Hidden: 7168ç»´ (mlp_ratio=1.0)
  - Output: 3072ç»´
  - Parameters: 147M
```

---

## ğŸ¯ å…³é”®æŒ‡æ ‡

### è®­ç»ƒç›®æ ‡

| æŒ‡æ ‡ | ç›®æ ‡å€¼ | è¯´æ˜ |
|-----|-------|------|
| **CosSim** | **>0.90** | æ ¸å¿ƒæŒ‡æ ‡ï¼šæ–¹å‘å¯¹é½åº¦ |
| Loss | è¶‹å‘0 | æ€»æŸå¤±ä¸‹é™ |
| Student Magnitude | ç¨³å®š | ä¸åº”åç¼©æˆ–çˆ†ç‚¸ |
| Training Speed | ~2-5s/it | RTX 4070 8GB |

### æ”¶æ•›é˜¶æ®µ

```
Step   0-50:  CosSim 0.20-0.50  ğŸ”„ é€‚åº”ä¸­
Step  50-100: CosSim 0.50-0.70  âš ï¸  å­¦ä¹ ä¸­
Step 100-200: CosSim 0.70-0.90  ğŸ“ˆ è‰¯å¥½
Step  200+:   CosSim >0.90      âœ…ä¼˜ç§€ â† ç›®æ ‡
```

---

## ğŸ”¬ å¯¹æ¯”æ€»ç»“

### vs ä¼ ç»ŸMSE

| ç‰¹æ€§ | MSE | Mercator |
|-----|-----|----------|
| å¯¹é½ç›®æ ‡ | æ•°å€¼ç›¸ç­‰ | æ–¹å‘ä¸€è‡´ |
| å¹…åº¦æ•æ„Ÿ | é«˜ âŒ | ä½ âœ… |
| è¯­ä¹‰ç†è§£ | å¼± | å¼º âœ… |
| RoPEå…¼å®¹ | ä¸€èˆ¬ | ä¼˜ç§€ âœ… |
| æ”¶æ•›é€Ÿåº¦ | æ…¢ | å¿« âœ… |

### vs å…¶ä»–æ–¹æ³•

| æ–¹æ³• | ä¼˜ç‚¹ | ç¼ºç‚¹ | ä½¿ç”¨åœºæ™¯ |
|-----|------|------|---------|
| **Mercator** | è¯­ä¹‰å¯¹é½å¼º | å¯èƒ½å¿½ç•¥å¹…åº¦ | ä¸»è¦æ–¹æ³•â­ |
| **Hybrid** | å¹³è¡¡ä¸¤è€… | éœ€è°ƒæƒé‡ | è¿‡æ¸¡é˜¶æ®µ |
| **Pure MSE** | ç®€å•ç›´æ¥ | è¯­ä¹‰å¼± | åŸºçº¿å¯¹æ¯” |

---

## âœ… æ€»ç»“

### æˆ‘ä»¬ä½¿ç”¨çš„å››ç§å¯¹é½æ–¹æ³•ï¼š

1. **Mercator Projection Loss** â­
   - å¯¹é½è¯­ä¹‰æ–¹å‘ï¼ˆä¸»è¦æ–¹æ³•ï¼‰
   - `loss = 1 - cosine_similarity`
   - ç›®æ ‡ï¼šCosSim > 0.90

2. **Hybrid Loss**
   - Mercator + MSEæ··åˆ
   - å¯è°ƒæƒé‡å¹³è¡¡

3. **Elastic Bottleneck Projector** â­
   - ç»´åº¦å¯¹é½ï¼š7168ç»´ â†’ 3072ç»´
   - å¯å­¦ä¹ çš„MLPæŠ•å½±ç½‘ç»œ
   - 147Må‚æ•°

4. **Cross-Layer Aggregation** â­
   - èšåˆæ‰€æœ‰å±‚çš„KV
   - Teacher: 28å±‚ Ã— 256 = 7168ç»´
   - Student: 24å±‚ Ã— 128 = 3072ç»´

### å®Œæ•´æµç¨‹ï¼š

```
Teacher Forward â†’ Cross-Layer Aggregation â†’ Type Conversion
                                              â†“
                                    Elastic Bottleneck
                                              â†“
                                    Mercator Loss â† Student KV
                                              â†“
                                         Backprop
```

**æ ¸å¿ƒåˆ›æ–°**ï¼šæ–¹å‘å¯¹é½ + è·¨å±‚èšåˆ + åŠ¨æ€ç»´åº¦æ£€æµ‹

**é€‚ç”¨åœºæ™¯**ï¼šRoPE-basedæ¨¡å‹ï¼ˆQwen/Llamaï¼‰çš„KV Cacheè’¸é¦
