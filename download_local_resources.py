"""
ğŸ”½ KAVA æœ¬åœ°èµ„æºä¸‹è½½å™¨
ä¸‹è½½æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®é›†åˆ°é¡¹ç›®æœ¬åœ°ï¼Œå®ç°å®Œå…¨ç¦»çº¿è®­ç»ƒ
"""

import os
import sys
from huggingface_hub import snapshot_download

# å®šä¹‰ä¸‹è½½é…ç½®
DOWNLOAD_CONFIG = {
    "models": {
        "Qwen/Qwen2.5-1.5B-Instruct": "local_models/qwen-1.5b-teacher",
        "Qwen/Qwen2.5-0.5B-Instruct": "local_models/qwen-0.5b-student"
    },
    "datasets": {
        "gsm8k": "local_data/gsm8k"
    }
}

def download_models():
    """ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°"""
    print("=" * 70)
    print("ğŸ“¦ Step 1: Downloading Models")
    print("=" * 70)
    
    for model_id, local_path in DOWNLOAD_CONFIG["models"].items():
        print(f"\nğŸ”½ Downloading {model_id}...")
        print(f"   Target: {local_path}")
        
        try:
            os.makedirs(local_path, exist_ok=True)
            
            snapshot_download(
                repo_id=model_id,
                local_dir=local_path,
                # ä»…ä¸‹è½½æ ¸å¿ƒæ–‡ä»¶ï¼Œå‡å°‘ä¸å¿…è¦çš„ä¸‹è½½é‡
                allow_patterns=[
                    "*.json",           # é…ç½®æ–‡ä»¶
                    "*.safetensors",    # æ¨¡å‹æƒé‡
                    "*.py",             # æ¨¡å‹ä»£ç 
                    "tokenizer*",       # åˆ†è¯å™¨æ–‡ä»¶
                    "*.model",          # åˆ†è¯å™¨æ¨¡å‹
                    "*.txt",            # å…¶ä»–é…ç½®
                    "generation_config.json",
                    "config.json",
                    "tokenizer_config.json"
                ],
                resume_download=True,
                local_dir_use_symlinks=False  # é¿å…ç¬¦å·é“¾æ¥é—®é¢˜
            )
            
            print(f"   âœ… {model_id} Download Complete!")
            
            # éªŒè¯å…³é”®æ–‡ä»¶
            required_files = ["config.json", "tokenizer_config.json"]
            missing_files = []
            for file in required_files:
                if not os.path.exists(os.path.join(local_path, file)):
                    missing_files.append(file)
            
            if missing_files:
                print(f"   âš ï¸ Warning: Missing files: {missing_files}")
            else:
                print(f"   âœ… All required files verified")
                
        except Exception as e:
            print(f"   âŒ Error downloading {model_id}: {e}")
            return False
    
    return True

def download_dataset():
    """ä¸‹è½½æ•°æ®é›†åˆ°æœ¬åœ°"""
    print("\n" + "=" * 70)
    print("ğŸ“¦ Step 2: Downloading Dataset (GSM8K)")
    print("=" * 70)
    
    try:
        from datasets import load_dataset
        
        dataset_path = DOWNLOAD_CONFIG["datasets"]["gsm8k"]
        os.makedirs(dataset_path, exist_ok=True)
        
        print(f"\nğŸ”½ Downloading GSM8K dataset...")
        print(f"   Target: {dataset_path}")
        
        # ä¸‹è½½æ•°æ®é›†
        dataset = load_dataset("gsm8k", "main")
        
        # ä¿å­˜åˆ°æœ¬åœ°
        dataset.save_to_disk(dataset_path)
        
        print(f"   âœ… GSM8K Download Complete!")
        print(f"   ğŸ“Š Train samples: {len(dataset['train'])}")
        print(f"   ğŸ“Š Test samples: {len(dataset['test'])}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Error downloading dataset: {e}")
        print("\n   ğŸ’¡ Troubleshooting:")
        print("   1. Check network connection")
        print("   2. Try HF mirror: export HF_ENDPOINT=https://hf-mirror.com")
        print("   3. Manual download: https://huggingface.co/datasets/gsm8k")
        return False

def verify_downloads():
    """éªŒè¯æ‰€æœ‰ä¸‹è½½æ˜¯å¦å®Œæˆ"""
    print("\n" + "=" * 70)
    print("ğŸ” Step 3: Verifying Downloads")
    print("=" * 70)
    
    all_valid = True
    
    # éªŒè¯æ¨¡å‹
    print("\nğŸ“‹ Models:")
    for model_id, local_path in DOWNLOAD_CONFIG["models"].items():
        if os.path.exists(local_path):
            # æ£€æŸ¥å…³é”®æ–‡ä»¶
            config_file = os.path.join(local_path, "config.json")
            if os.path.exists(config_file):
                # è·å–æ–‡ä»¶å¤§å°
                total_size = sum(
                    os.path.getsize(os.path.join(dirpath, filename))
                    for dirpath, _, filenames in os.walk(local_path)
                    for filename in filenames
                )
                size_gb = total_size / (1024 ** 3)
                print(f"   âœ… {model_id}")
                print(f"      Path: {local_path}")
                print(f"      Size: {size_gb:.2f} GB")
            else:
                print(f"   âŒ {model_id} - Missing config.json")
                all_valid = False
        else:
            print(f"   âŒ {model_id} - Directory not found")
            all_valid = False
    
    # éªŒè¯æ•°æ®é›†
    print("\nğŸ“‹ Datasets:")
    for dataset_name, local_path in DOWNLOAD_CONFIG["datasets"].items():
        if os.path.exists(local_path):
            dataset_json = os.path.join(local_path, "dataset_info.json")
            if os.path.exists(dataset_json):
                total_size = sum(
                    os.path.getsize(os.path.join(dirpath, filename))
                    for dirpath, _, filenames in os.walk(local_path)
                    for filename in filenames
                )
                size_mb = total_size / (1024 ** 2)
                print(f"   âœ… {dataset_name}")
                print(f"      Path: {local_path}")
                print(f"      Size: {size_mb:.2f} MB")
            else:
                print(f"   âŒ {dataset_name} - Missing dataset_info.json")
                all_valid = False
        else:
            print(f"   âŒ {dataset_name} - Directory not found")
            all_valid = False
    
    return all_valid

def main():
    print("\n" + "ğŸ¯" * 35)
    print("  KAVA Local Resource Downloader")
    print("  å®Œå…¨æœ¬åœ°åŒ–è®­ç»ƒç¯å¢ƒæ­å»ºå·¥å…·")
    print("ğŸ¯" * 35 + "\n")
    
    print("ğŸ“ Download Plan:")
    print("   Models:")
    for model_id, path in DOWNLOAD_CONFIG["models"].items():
        print(f"      â€¢ {model_id} â†’ {path}")
    print("   Datasets:")
    for dataset_id, path in DOWNLOAD_CONFIG["datasets"].items():
        print(f"      â€¢ {dataset_id} â†’ {path}")
    
    print("\nâš ï¸ Note: This may take 10-30 minutes depending on your network speed.")
    print("          Total download size: ~3-4 GB")
    
    input("\nPress Enter to start downloading...")
    
    # æ‰§è¡Œä¸‹è½½
    success = True
    
    # Step 1: ä¸‹è½½æ¨¡å‹
    if not download_models():
        success = False
        print("\nâŒ Model download failed!")
    
    # Step 2: ä¸‹è½½æ•°æ®é›†
    if not download_dataset():
        success = False
        print("\nâŒ Dataset download failed!")
    
    # Step 3: éªŒè¯
    if success and verify_downloads():
        print("\n" + "=" * 70)
        print("ğŸ‰ SUCCESS! All resources downloaded successfully!")
        print("=" * 70)
        print("\nğŸ“‚ Project Structure:")
        print("   .")
        print("   â”œâ”€â”€ local_models/")
        print("   â”‚   â”œâ”€â”€ qwen-1.5b-teacher/")
        print("   â”‚   â””â”€â”€ qwen-0.5b-student/")
        print("   â””â”€â”€ local_data/")
        print("       â””â”€â”€ gsm8k/")
        print("\nâœ… Ready to run: python train_local_only.py")
        return 0
    else:
        print("\n" + "=" * 70)
        print("âš ï¸ Download completed with errors. Please check the logs above.")
        print("=" * 70)
        return 1

if __name__ == "__main__":
    try:
        exit_code = main()
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Download interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
