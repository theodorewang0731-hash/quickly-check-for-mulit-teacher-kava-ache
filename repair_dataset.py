"""
ğŸ”§ GSM8K æ•°æ®é›†ä¿®å¤è„šæœ¬
ç¡®ä¿æ•°æ®é›†ç»“æ„å®Œæ•´ï¼ŒåŒ…å« dataset_info.json ç­‰å…ƒæ•°æ®
"""

import os
import shutil
from datasets import load_dataset

DATA_DIR = "local_data/gsm8k"

def repair_dataset():
    """ä¿®å¤å¹¶é‡å»ºå®Œæ•´çš„ GSM8K æ•°æ®é›†ç»“æ„"""
    
    print("\n" + "=" * 70)
    print("ğŸ”§ GSM8K Dataset Repair Tool")
    print("=" * 70)
    
    # 1. åˆ é™¤æ—§çš„/ä¸å®Œæ•´çš„æœ¬åœ°æ•°æ®æ–‡ä»¶å¤¹
    if os.path.exists(DATA_DIR):
        print(f"\nğŸ—‘ï¸ Deleting incomplete data folder: {DATA_DIR}")
        try:
            shutil.rmtree(DATA_DIR)
            print("   âœ… Old folder removed")
        except Exception as e:
            print(f"   âš ï¸ Warning: Could not remove folder: {e}")
            print("   Attempting to continue...")
    else:
        print(f"\nğŸ“ Data folder not found (will create new): {DATA_DIR}")
    
    # 2. ä» Hugging Face Hub (æˆ–ç¼“å­˜) é‡æ–°åŠ è½½ GSM8K
    print("\nğŸŒ Loading GSM8K from HuggingFace (cache or hub)...")
    print("   This may take a few minutes on first run...")
    
    try:
        # åŠ è½½å®Œæ•´çš„æ•°æ®é›†ï¼ˆåŒ…å« train å’Œ test splitï¼‰
        print("   Loading train split...")
        dataset = load_dataset("gsm8k", "main")
        
        print(f"   âœ… Dataset loaded successfully!")
        print(f"      Train samples: {len(dataset['train'])}")
        print(f"      Test samples: {len(dataset['test'])}")
        
    except Exception as e:
        print(f"\nâŒ Critical Error during dataset loading: {e}")
        print("\nğŸ’¡ Troubleshooting:")
        print("   1. Check network connection")
        print("   2. Try HF mirror (China users):")
        print("      PowerShell: $env:HF_ENDPOINT='https://hf-mirror.com'")
        print("      Then re-run this script")
        print("   3. Clear HuggingFace cache:")
        print("      Remove: ~/.cache/huggingface/ (Linux/Mac)")
        print("      Remove: %USERPROFILE%\\.cache\\huggingface\\ (Windows)")
        return False
    
    # 3. åˆ›å»ºæœ¬åœ°ç›®å½•
    print(f"\nğŸ’¾ Saving complete dataset structure to {DATA_DIR}...")
    os.makedirs(DATA_DIR, exist_ok=True)
    
    try:
        # å¼ºåˆ¶ä¿å­˜åˆ°æœ¬åœ°è·¯å¾„ï¼Œç”Ÿæˆå®Œæ•´çš„ç»“æ„æ–‡ä»¶ (åŒ…æ‹¬ dataset_info.json)
        dataset.save_to_disk(DATA_DIR)
        
        print("   âœ… Dataset saved successfully!")
        
    except Exception as e:
        print(f"\nâŒ Error saving dataset: {e}")
        print("\nğŸ’¡ Possible causes:")
        print("   1. Insufficient disk space (need ~100 MB)")
        print("   2. Permission denied (check folder permissions)")
        print("   3. Path too long (try shorter path)")
        return False
    
    # 4. éªŒè¯å…³é”®æ–‡ä»¶
    print("\nğŸ” Verifying dataset structure...")
    
    required_files = [
        "dataset_info.json",
        "state.json"
    ]
    
    missing_files = []
    for file in required_files:
        file_path = os.path.join(DATA_DIR, file)
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            print(f"   âœ… {file} ({file_size} bytes)")
        else:
            print(f"   âŒ {file} - MISSING")
            missing_files.append(file)
    
    # æ£€æŸ¥ train å’Œ test ç›®å½•
    for split in ["train", "test"]:
        split_dir = os.path.join(DATA_DIR, split)
        if os.path.exists(split_dir):
            print(f"   âœ… {split}/ directory exists")
        else:
            print(f"   âŒ {split}/ directory - MISSING")
            missing_files.append(f"{split}/")
    
    if missing_files:
        print(f"\nâš ï¸ Warning: Missing files/directories: {missing_files}")
        print("   Dataset may still work, but structure is incomplete.")
        return False
    
    # 5. æœ€ç»ˆéªŒè¯ - å°è¯•ä»ç£ç›˜åŠ è½½
    print("\nğŸ§ª Testing load from disk...")
    try:
        from datasets import load_from_disk
        test_dataset = load_from_disk(DATA_DIR)
        
        print(f"   âœ… Load test successful!")
        print(f"      Splits available: {list(test_dataset.keys())}")
        print(f"      Train samples: {len(test_dataset['train'])}")
        
    except Exception as e:
        print(f"   âŒ Load test failed: {e}")
        return False
    
    # æˆåŠŸï¼
    print("\n" + "=" * 70)
    print("ğŸ‰ SUCCESS! Dataset repair completed!")
    print("=" * 70)
    print(f"\nğŸ“‚ Dataset location: {DATA_DIR}")
    print(f"ğŸ“Š Total samples: {len(test_dataset['train']) + len(test_dataset['test'])}")
    print(f"   - Train: {len(test_dataset['train'])}")
    print(f"   - Test: {len(test_dataset['test'])}")
    print("\nâœ… Ready to run: python train_local_only.py")
    print("=" * 70 + "\n")
    
    return True

if __name__ == "__main__":
    try:
        success = repair_dataset()
        
        if success:
            print("âœ¨ Next step: python train_local_only.py")
            exit(0)
        else:
            print("\nâš ï¸ Dataset repair completed with warnings.")
            print("   You may try running train_local_only.py anyway.")
            exit(1)
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Repair interrupted by user")
        exit(1)
        
    except Exception as e:
        print(f"\n\nâŒ Unexpected error: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
