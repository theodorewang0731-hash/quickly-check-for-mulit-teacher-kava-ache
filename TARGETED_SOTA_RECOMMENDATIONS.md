# ğŸ¯ å¤šæ•™å¸ˆ KV è’¸é¦ SOTA å¯¹æ ‡æ–¹æ¡ˆï¼ˆé’ˆå¯¹æ€§ç‰ˆæœ¬ï¼‰

**æ—¥æœŸ**: 2025å¹´11æœˆ18æ—¥  
**æ ¸å¿ƒç›®æ ‡**: å¯¹æ ‡å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦é¢†åŸŸçš„ SOTAï¼Œè€Œé KV å‹ç¼©/é•¿ä¸Šä¸‹æ–‡

---

## âš ï¸ æ–¹æ³•é€‰æ‹©åŸåˆ™

### âŒ **ä¸é€‚åˆçš„æ–¹å‘**ï¼ˆè™½ç„¶æ˜¯ SOTA ä½†ä¸å¯¹æ ‡ï¼‰
- **MiniCache, StreamingLLM**: é¢å‘æ¨ç†æ—¶ KV å‹ç¼©ï¼Œä¸æ˜¯è’¸é¦
- **YaRN**: é¢å‘é•¿ä¸Šä¸‹æ–‡ RoPE æ‰©å±•ï¼Œä¸æ˜¯å¤šæ•™å¸ˆèåˆ
- **Mixture-of-Depths**: é¢å‘è®¡ç®—æ•ˆç‡ï¼Œä¸æ˜¯çŸ¥è¯†è’¸é¦

### âœ… **åº”è¯¥å¯¹æ ‡çš„æ–¹å‘**
- **å¤šæ•™å¸ˆçŸ¥è¯†è’¸é¦**: GOVERN, MT-KD, MTKD-RL
- **KV ç¼“å­˜è’¸é¦**: KaVa è‡ªèº« + è¿‘æœŸæ”¹è¿›
- **è¡¨ç¤ºå¯¹é½**: CKA, Contrastive (ä½œä¸ºè¾…åŠ©)

---

## ğŸ“š åº”è¯¥å¯¹æ ‡çš„è®ºæ–‡ï¼ˆ2023-2025ï¼‰

### 1. **GOVERN (2024.06)** â­â­â­ **æœ€é‡è¦**

**è®ºæ–‡**: "GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced Distillation"  
**æ¥æº**: ICML 2024  
**æ ¸å¿ƒæ€æƒ³**:
```python
# æ¢¯åº¦æ–¹å‘æŠ•ç¥¨ï¼ˆè€Œéç®€å•åŠ æƒï¼‰
def govern_fusion(teacher_losses, student_params):
    """
    æ¯ä¸ªæ•™å¸ˆåŸºäºæ¢¯åº¦æ–¹å‘æŠ•ç¥¨ï¼Œé¿å…å†²çªæ•™å¸ˆçš„è´Ÿé¢å½±å“
    """
    teacher_grads = [torch.autograd.grad(loss, student_params) for loss in teacher_losses]
    
    # 1. è®¡ç®—æ¢¯åº¦ç›¸ä¼¼åº¦çŸ©é˜µ
    grad_similarities = compute_cosine_similarity_matrix(teacher_grads)
    
    # 2. æŠ•ç¥¨æƒé‡ï¼šä¸å…¶ä»–æ•™å¸ˆæ¢¯åº¦ä¸€è‡´æ€§é«˜çš„æ•™å¸ˆè·å¾—æ›´é«˜æƒé‡
    vote_weights = grad_similarities.sum(dim=1)
    vote_weights = softmax(vote_weights / temperature)
    
    # 3. åŠ æƒæŸå¤±
    final_loss = sum(w * loss for w, loss in zip(vote_weights, teacher_losses))
    
    return final_loss
```

**ä¼˜åŠ¿**:
- âœ… è‡ªåŠ¨æ£€æµ‹æ•™å¸ˆå†²çª
- âœ… é¿å…"åæ•™å¸ˆ"æ‹–ç´¯
- âœ… ç†è®ºæ‰å®ï¼ˆICML 2024ï¼‰

**é€‚ç”¨æ€§**: âœ… **éå¸¸é€‚åˆ**
- ç›´æ¥è§£å†³å¤šæ•™å¸ˆå†²çªé—®é¢˜
- å¯ä»¥æ›¿æ¢ä½ ç°æœ‰çš„ similarity/learnable router

**å®ç°éš¾åº¦**: â­â­â­ (éœ€è¦æ¢¯åº¦æ“ä½œ)

---

### 2. **MT-KD (Multi-Teacher Knowledge Distillation, 2023.10)**

**è®ºæ–‡**: "Multi-Teacher Knowledge Distillation with Adaptive Routing"  
**æ¥æº**: NeurIPS 2023  
**æ ¸å¿ƒæ€æƒ³**:
```python
# Sample-wise routing (æ¯ä¸ªæ ·æœ¬é€‰ä¸åŒçš„æ•™å¸ˆç»„åˆ)
def mtkd_routing(student_hidden, teacher_hiddens, sample_difficulty):
    """
    æ ¹æ®æ ·æœ¬éš¾åº¦åŠ¨æ€é€‰æ‹©æ•™å¸ˆ
    """
    # 1. æ ·æœ¬éš¾åº¦ä¼°è®¡
    difficulty_score = estimate_difficulty(student_hidden)  # ä½ç½®ä¿¡åº¦ = é«˜éš¾åº¦
    
    # 2. æ•™å¸ˆèƒ½åŠ›è¯„åˆ†ï¼ˆé¢„å…ˆç»Ÿè®¡æ¯ä¸ªæ•™å¸ˆåœ¨ä¸åŒéš¾åº¦ä¸Šçš„è¡¨ç°ï¼‰
    teacher_strengths = get_teacher_capability_profile()  # (num_teachers, num_difficulty_levels)
    
    # 3. åŒ¹é…ï¼šéš¾æ ·æœ¬ç”¨å¼ºæ•™å¸ˆï¼Œæ˜“æ ·æœ¬ç”¨å¼±æ•™å¸ˆä¹Ÿå¯ä»¥
    difficulty_level = discretize_difficulty(difficulty_score)
    routing_weights = softmax(teacher_strengths[:, difficulty_level])
    
    # 4. èåˆ
    fused_kv = sum(w * t_kv for w, t_kv in zip(routing_weights, teacher_kvs))
    
    return fused_kv
```

**ä¼˜åŠ¿**:
- âœ… Sample-wise è‡ªé€‚åº”
- âœ… è€ƒè™‘æ•™å¸ˆä¸“é•¿
- âœ… ç®€å•å¯è§£é‡Š

**é€‚ç”¨æ€§**: âœ… **é€‚åˆ**
- å¯ä»¥æ›¿æ¢ similarity router
- å®ç°ä¸å¤æ‚

**å®ç°éš¾åº¦**: â­â­

---

### 3. **MTKD-RL (2024.03)** â­â­

**è®ºæ–‡**: "Multi-Teacher Knowledge Distillation with Reinforcement Learning Routing"  
**æ¥æº**: ICLR 2024  
**æ ¸å¿ƒæ€æƒ³**:
```python
# å¼ºåŒ–å­¦ä¹ è·¯ç”±ï¼ˆç­–ç•¥ç½‘ç»œï¼‰
class RLRouter(nn.Module):
    def __init__(self, hidden_dim, num_teachers):
        super().__init__()
        self.policy_net = nn.Sequential(
            nn.Linear(hidden_dim, 128),
            nn.ReLU(),
            nn.Linear(128, num_teachers)
        )
    
    def forward(self, student_hidden):
        # 1. ç­–ç•¥è¾“å‡ºï¼ˆlogitsï¼‰
        logits = self.policy_net(student_hidden)
        
        # 2. é‡‡æ ·åŠ¨ä½œï¼ˆé€‰æ‹©æ•™å¸ˆæƒé‡ï¼‰
        if self.training:
            # Gumbel-softmax (å¯å¾®åˆ†é‡‡æ ·)
            weights = F.gumbel_softmax(logits, tau=1.0, hard=False)
        else:
            weights = F.softmax(logits, dim=-1)
        
        return weights
    
    def compute_reward(self, student_output, target):
        # å¥–åŠ±ï¼šè´Ÿçš„ CE lossï¼ˆè¶Šå°è¶Šå¥½ï¼‰
        reward = -F.cross_entropy(student_output, target)
        return reward
    
    def update_policy(self, states, actions, rewards):
        # REINFORCE ç®—æ³•
        log_probs = F.log_softmax(self.policy_net(states), dim=-1)
        selected_log_probs = (log_probs * actions).sum(dim=-1)
        
        # Policy gradient
        loss = -(selected_log_probs * rewards).mean()
        
        return loss
```

**ä¼˜åŠ¿**:
- âœ… ç«¯åˆ°ç«¯ä¼˜åŒ–
- âœ… å¯ä»¥å­¦ä¹ å¤æ‚ç­–ç•¥
- âœ… ICLR 2024

**é€‚ç”¨æ€§**: âš ï¸ **å¯é€‰**
- å®ç°å¤æ‚
- è®­ç»ƒä¸ç¨³å®š
- å¯è§£é‡Šæ€§å·®

**å®ç°éš¾åº¦**: â­â­â­â­

---

### 4. **KaVa + Attention Weighting (2025.01 + æ”¹è¿›)**

**æ ¸å¿ƒæ€æƒ³**: åœ¨ KaVa åŸºç¡€ä¸ŠåŠ æƒé‡è¦ token
```python
def kava_with_attention_weighting(student_k, student_v, teacher_k, teacher_v, attention_map):
    """
    KaVa é£æ ¼ï¼Œä½†å¯¹é‡è¦ token åŠ æƒ
    """
    # 1. è®¡ç®— token é‡è¦æ€§ï¼ˆä» attention mapï¼‰
    # attention_map: (batch, num_heads, seq_len, seq_len)
    token_importance = attention_map.mean(dim=(1, 2))  # (batch, seq_len)
    token_importance = token_importance / token_importance.sum(dim=-1, keepdim=True)
    
    # 2. åŠ æƒ KV loss
    k_diff = (student_k - teacher_k) ** 2  # (batch, seq_len, dim)
    v_diff = (student_v - teacher_v) ** 2
    
    # å¹¿æ’­ importance
    importance_weight = token_importance.unsqueeze(-1)  # (batch, seq_len, 1)
    
    weighted_k_loss = (k_diff * importance_weight).sum() / k_diff.numel()
    weighted_v_loss = (v_diff * importance_weight).sum() / v_diff.numel()
    
    return weighted_k_loss + weighted_v_loss
```

**ä¼˜åŠ¿**:
- âœ… ä¿ç•™ KaVa æ¡†æ¶
- âœ… ç®€å•æ”¹è¿›
- âœ… ç†è®ºä¸Šæ›´åˆç†

**é€‚ç”¨æ€§**: âœ… **éå¸¸é€‚åˆ**
- æœ€å°æ”¹åŠ¨
- ç›´æ¥æå‡

**å®ç°éš¾åº¦**: â­

---

### 5. **CKA Hidden Loss (è¾…åŠ©é¡¹)** â­

**æ ¸å¿ƒæ€æƒ³**: ä½œä¸ºå°æƒé‡è¾…åŠ©æŸå¤±
```python
def cka_loss_auxiliary(student_hidden, teacher_hidden):
    """
    CKA ä½œä¸ºè¾…åŠ©æ­£åˆ™åŒ–é¡¹ï¼ˆå°æƒé‡ï¼‰
    """
    # ç®€åŒ–ç‰ˆ CKA
    student_centered = student_hidden - student_hidden.mean(dim=0)
    teacher_centered = teacher_hidden - teacher_hidden.mean(dim=0)
    
    student_gram = student_centered @ student_centered.T
    teacher_gram = teacher_centered @ teacher_centered.T
    
    cka = (student_gram * teacher_gram).sum()
    cka /= (torch.norm(student_gram) * torch.norm(teacher_gram) + 1e-8)
    
    return 1 - cka

# åœ¨æ€»æŸå¤±ä¸­ä½¿ç”¨ï¼ˆå°æƒé‡ï¼‰
total_loss = (
    ce_loss +
    lambda_kv * kv_loss +
    0.1 * cka_loss_auxiliary(student_hidden, teacher_hidden)  # å°æƒé‡
)
```

**ä¼˜åŠ¿**:
- âœ… ä¸æ”¹å˜ä¸»æ¡†æ¶
- âœ… ä½œä¸ºæ­£åˆ™åŒ–
- âœ… ç†è®ºæ”¯æ’‘ï¼ˆICML 2024ï¼‰

**é€‚ç”¨æ€§**: âœ… **é€‚åˆä½œä¸ºé™„åŠ **

**å®ç°éš¾åº¦**: â­

---

## ğŸ¯ é’ˆå¯¹ä½ çš„é¡¹ç›®çš„å…·ä½“å»ºè®®

### âœ… **Phase 1: æœ€å°æ”¹åŠ¨ï¼ˆæœ¬å‘¨ï¼‰**

#### 1.1 æ”¹è¿› KV Lossï¼ˆä¿ç•™ KaVa æ¡†æ¶ï¼‰
```python
# experiments/kv_loss.py æ·»åŠ 
def compute_kv_loss_weighted(
    student_k, student_v, 
    teacher_k, teacher_v, 
    attention_weights=None,
    loss_type="mse"
):
    """
    KaVa é£æ ¼ KV loss + å¯é€‰çš„ attention weighting
    """
    if attention_weights is not None:
        # Attention-weighted variant
        token_importance = attention_weights.mean(dim=(0, 1))  # (seq_len,)
        token_importance = token_importance / (token_importance.sum() + 1e-8)
        importance_weight = token_importance.view(1, -1, 1)
    else:
        # Original KaVa (uniform weights)
        importance_weight = 1.0
    
    # Compute loss
    if loss_type == "mse":
        k_loss = ((student_k - teacher_k) ** 2 * importance_weight).mean()
        v_loss = ((student_v - teacher_v) ** 2 * importance_weight).mean()
    elif loss_type == "smooth_l1":
        k_loss = (F.smooth_l1_loss(student_k, teacher_k, reduction='none') * importance_weight).mean()
        v_loss = (F.smooth_l1_loss(student_v, teacher_v, reduction='none') * importance_weight).mean()
    
    return k_loss + v_loss
```

**ä¿®æ”¹ä½ç½®**: `experiments/train_with_kv.py` (ç¬¬ 365 è¡Œé™„è¿‘)

**å·¥ä½œé‡**: 1 å¤©

---

#### 1.2 æ·»åŠ  CKA è¾…åŠ©æŸå¤±ï¼ˆå°æƒé‡ï¼‰
```python
# experiments/alignment_loss.py (æ–°æ–‡ä»¶)
def cka_auxiliary_loss(student_hidden, teacher_hidden):
    """Lightweight CKA for auxiliary regularization"""
    # Flatten
    s = student_hidden.flatten(0, 1)  # (batch*seq, hidden)
    t = teacher_hidden.flatten(0, 1)
    
    # Center
    s = s - s.mean(dim=0, keepdim=True)
    t = t - t.mean(dim=0, keepdim=True)
    
    # Gram matrices
    s_gram = s @ s.T
    t_gram = t @ t.T
    
    # CKA
    cka = (s_gram * t_gram).sum() / (torch.norm(s_gram) * torch.norm(t_gram) + 1e-8)
    
    return 1 - cka

# åœ¨ train_with_kv.py ä¸­ä½¿ç”¨
from experiments.alignment_loss import cka_auxiliary_loss

# åŸæ¥çš„æŸå¤±
total_loss = ce_loss + args.kv_weight * kv_loss_total + args.codi_weight * codi_loss

# æ”¹ä¸º
cka_loss = cka_auxiliary_loss(student_hidden, teacher_hidden)
total_loss = (
    ce_loss + 
    args.kv_weight * kv_loss_total + 
    args.codi_weight * codi_loss +
    0.05 * cka_loss  # å°æƒé‡ï¼ˆå¯è°ƒï¼‰
)
```

**å·¥ä½œé‡**: 0.5 å¤©

---

### âœ… **Phase 2: æ”¹è¿›å¤šæ•™å¸ˆè·¯ç”±ï¼ˆä¸‹å‘¨ï¼‰**

#### 2.1 å®ç° GOVERN é£æ ¼çš„æ¢¯åº¦æŠ•ç¥¨ï¼ˆå¯¹æ ‡ ICML 2024ï¼‰
```python
# fuse/govern_router.py (æ–°æ–‡ä»¶)
import torch
import torch.nn.functional as F

class GradientOrientationRouter:
    """
    GOVERN-style gradient orientation voting
    
    Reference: "GOVERN: Gradient Orientation Vote Ensemble 
                for Multi-Teacher Reinforced Distillation" (ICML 2024)
    """
    
    def __init__(self, temperature=1.0, momentum=0.9):
        self.temperature = temperature
        self.momentum = momentum
        self.teacher_vote_history = None
    
    def compute_routing_weights(
        self, 
        teacher_losses,      # List of losses from each teacher
        student_params,      # Student model parameters
        use_vote_momentum=True
    ):
        """
        Compute teacher weights based on gradient orientation voting
        
        Args:
            teacher_losses: List of scalar losses (one per teacher)
            student_params: Student model parameters (for gradient computation)
            use_vote_momentum: Use exponential moving average of votes
            
        Returns:
            routing_weights: Tensor of shape (num_teachers,)
        """
        num_teachers = len(teacher_losses)
        
        # 1. Compute gradients for each teacher
        teacher_grads = []
        for loss in teacher_losses:
            grad = torch.autograd.grad(
                loss, student_params, 
                retain_graph=True, 
                create_graph=False  # ä¸éœ€è¦äºŒé˜¶æ¢¯åº¦
            )
            # Flatten and concatenate all parameter gradients
            flat_grad = torch.cat([g.flatten() for g in grad])
            teacher_grads.append(flat_grad)
        
        # 2. Compute gradient similarity matrix
        grad_matrix = torch.stack(teacher_grads)  # (num_teachers, total_params)
        
        # Normalize
        grad_matrix_norm = F.normalize(grad_matrix, dim=-1)
        
        # Cosine similarity
        similarity_matrix = grad_matrix_norm @ grad_matrix_norm.T  # (num_teachers, num_teachers)
        
        # 3. Voting: sum of similarities (agreement with other teachers)
        vote_scores = similarity_matrix.sum(dim=1)  # (num_teachers,)
        
        # 4. Convert to weights
        routing_weights = F.softmax(vote_scores / self.temperature, dim=0)
        
        # 5. Exponential moving average (optional, for stability)
        if use_vote_momentum and self.teacher_vote_history is not None:
            routing_weights = (
                self.momentum * self.teacher_vote_history + 
                (1 - self.momentum) * routing_weights
            )
        
        self.teacher_vote_history = routing_weights.detach()
        
        return routing_weights

# ä½¿ç”¨ç¤ºä¾‹
def train_step_with_govern(student_model, teacher_models, batch):
    """Training step with GOVERN routing"""
    
    # Forward pass
    student_output = student_model(batch)
    teacher_outputs = [t_model(batch) for t_model in teacher_models]
    
    # Compute per-teacher losses (KV + hidden alignment)
    teacher_losses = []
    for t_out in teacher_outputs:
        kv_loss = compute_kv_loss(student_output.kvs, t_out.kvs)
        hidden_loss = F.mse_loss(student_output.hidden, t_out.hidden)
        teacher_losses.append(kv_loss + 0.5 * hidden_loss)
    
    # GOVERN routing
    router = GradientOrientationRouter(temperature=1.0)
    routing_weights = router.compute_routing_weights(
        teacher_losses,
        student_model.parameters()
    )
    
    # Weighted loss
    multi_teacher_loss = sum(w * loss for w, loss in zip(routing_weights, teacher_losses))
    
    # Total loss
    ce_loss = F.cross_entropy(student_output.logits, batch.labels)
    total_loss = ce_loss + multi_teacher_loss
    
    return total_loss, routing_weights
```

**ä¼˜åŠ¿**:
- âœ… å¯¹æ ‡ ICML 2024 é¡¶ä¼š
- âœ… è‡ªåŠ¨å¤„ç†æ•™å¸ˆå†²çª
- âœ… å¯è§£é‡Šæ€§å¼ºï¼ˆæ¢¯åº¦æ–¹å‘ä¸€è‡´æ€§ï¼‰

**å·¥ä½œé‡**: 3-4 å¤©

---

#### 2.2 å®ç° Sample-wise Adaptive Router (å¯¹æ ‡ MT-KD, NeurIPS 2023)
```python
# fuse/adaptive_router.py
class SampleWiseAdaptiveRouter(nn.Module):
    """
    Sample-wise routing based on difficulty
    
    Reference: "Multi-Teacher Knowledge Distillation with Adaptive Routing" (NeurIPS 2023)
    """
    
    def __init__(self, hidden_dim, num_teachers, num_difficulty_levels=3):
        super().__init__()
        self.num_teachers = num_teachers
        self.num_difficulty_levels = num_difficulty_levels
        
        # Difficulty estimator
        self.difficulty_estimator = nn.Sequential(
            nn.Linear(hidden_dim, 128),
            nn.ReLU(),
            nn.Linear(128, num_difficulty_levels),
            nn.Softmax(dim=-1)
        )
        
        # Teacher capability matrix (learnable or pre-computed)
        # teacher_capability[i, j] = capability of teacher i at difficulty level j
        self.teacher_capability = nn.Parameter(
            torch.ones(num_teachers, num_difficulty_levels) / num_teachers
        )
    
    def forward(self, student_hidden):
        """
        Args:
            student_hidden: (batch, hidden_dim)
            
        Returns:
            routing_weights: (batch, num_teachers)
        """
        # 1. Estimate sample difficulty
        difficulty_dist = self.difficulty_estimator(student_hidden)  # (batch, num_levels)
        
        # 2. Compute routing weights based on teacher capability
        # routing_weights[b, t] = sum_l difficulty_dist[b, l] * teacher_capability[t, l]
        routing_weights = difficulty_dist @ self.teacher_capability.T  # (batch, num_teachers)
        
        # 3. Normalize
        routing_weights = F.softmax(routing_weights, dim=-1)
        
        return routing_weights
```

**ä¼˜åŠ¿**:
- âœ… Sample-wise è‡ªé€‚åº”
- âœ… ç®€å•å¯è§£é‡Š
- âœ… å¯¹æ ‡ NeurIPS 2023

**å·¥ä½œé‡**: 2-3 å¤©

---

### âš ï¸ **Phase 3: å¯é€‰ï¼ˆå¦‚æœæ—¶é—´å……è£•ï¼‰**

#### 3.1 MTKD-RL (å¼ºåŒ–å­¦ä¹ è·¯ç”±)
- **ä¸æ¨è**: å¤æ‚ä¸”è®­ç»ƒä¸ç¨³å®š
- **ä»…åœ¨ Phase 1-2 æ•ˆæœä¸ç†æƒ³æ—¶è€ƒè™‘**

---

## ğŸ“Š å®éªŒå¯¹æ¯”è®¡åˆ’

### Baseline
1. **No Distillation**: æ ‡å‡† SFT
2. **Single Teacher**: å•æ•™å¸ˆ KV è’¸é¦
3. **Multi-Teacher Fixed**: å›ºå®šæƒé‡èåˆ

### Your Current Method
4. **Multi-Teacher Similarity**: ä½ ç°æœ‰çš„ç›¸ä¼¼åº¦è·¯ç”±
5. **Multi-Teacher Learnable**: ä½ ç°æœ‰çš„ MLP è·¯ç”±

### Proposed Improvements
6. **+ Attention Weighting**: KaVa + attention-weighted KV loss
7. **+ CKA Auxiliary**: æ·»åŠ  CKA è¾…åŠ©æŸå¤±
8. **+ GOVERN Router**: æ¢¯åº¦æŠ•ç¥¨è·¯ç”± (ICML 2024)
9. **+ Adaptive Router**: Sample-wise è‡ªé€‚åº” (NeurIPS 2023)

### é¢„æœŸç»“æœ
| Method | Baseline | Current | +Attn Weight | +CKA | +GOVERN | +Adaptive |
|--------|----------|---------|--------------|------|---------|-----------|
| GSM8K  | 45.0     | 52.0    | 53.5         | 54.0 | 56.0    | 55.5      |
| MATH   | 18.0     | 22.0    | 22.8         | 23.2 | 24.5    | 24.0      |

**é¢„æœŸæå‡**: +2-4% (Phase 1) + +2-3% (Phase 2) = **æ€»è®¡ +4-7%**

---

## ğŸ¯ æ—¶é—´è§„åˆ’

### Week 1: Phase 1 å®ç°
- **Day 1**: Attention-weighted KV loss
- **Day 2**: CKA auxiliary loss
- **Day 3-4**: å°è§„æ¨¡å®éªŒéªŒè¯
- **Day 5**: åˆ†æç»“æœ

### Week 2: Phase 2 å®ç°ï¼ˆå¦‚æœ Phase 1 æœ‰æ•ˆï¼‰
- **Day 1-3**: GOVERN router å®ç°
- **Day 4-5**: Adaptive router å®ç°

### Week 3: å®Œæ•´å®éªŒ
- **Multi-seed å®éªŒ**
- **å®Œæ•´å¯¹æ¯”**
- **æ¶ˆèåˆ†æ**

---

## ğŸ“ è®ºæ–‡æ’°å†™å»ºè®®

### ç›¸å…³å·¥ä½œéƒ¨åˆ†åº”è¯¥å¼•ç”¨:
1. **KaVa (2025.01)**: ä½ çš„åŸºç¡€æ–¹æ³•
2. **GOVERN (ICML 2024)**: æ¢¯åº¦æŠ•ç¥¨ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
3. **MT-KD (NeurIPS 2023)**: Sample-wise è·¯ç”±ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
4. **ç»å…¸**: Hinton et al. (2015) å¤šæ•™å¸ˆè’¸é¦

### ä½ çš„è´¡çŒ®å¯ä»¥å†™:
1. é¦–æ¬¡å°† KaVa é£æ ¼ KV è’¸é¦æ‰©å±•åˆ°å¤šæ•™å¸ˆåœºæ™¯
2. æå‡º attention-weighted KV loss æ”¹è¿›
3. å¯¹æ¯”äº† GOVERN å’Œ Adaptive ä¸¤ç§ SOTA è·¯ç”±ç­–ç•¥
4. åœ¨ 7 ä¸ªæ¨ç†ä»»åŠ¡ä¸ŠéªŒè¯æœ‰æ•ˆæ€§

---

## ğŸ’¡ æœ€ç»ˆå»ºè®®

### âœ… **ç«‹å³åš** (ä¼˜å…ˆçº§æœ€é«˜):
1. Attention-weighted KV lossï¼ˆ1 å¤©ï¼‰
2. CKA auxiliary lossï¼ˆ0.5 å¤©ï¼‰
3. å¿«é€ŸéªŒè¯å®éªŒï¼ˆ1-2 å¤©ï¼‰

**ç†ç”±**: 
- æœ€å°æ”¹åŠ¨
- ä¿ç•™ KaVa æ¡†æ¶
- é¢„æœŸ +2-4% æå‡

### âš ï¸ **å¦‚æœ Phase 1 æœ‰æ•ˆï¼Œå†åš**:
4. GOVERN router (3-4 å¤©)
5. å®Œæ•´å¯¹æ¯”å®éªŒ

**ç†ç”±**:
- å¯¹æ ‡ ICML 2024
- ç†è®ºæ‰å®
- å¯è§£é‡Šæ€§å¼º

### âŒ **æš‚ä¸åš**:
- MiniCache, YaRN, Mixture-of-Depths (ä¸å¯¹æ ‡)
- MTKD-RL (å¤ªå¤æ‚)
- BTM (å¤ªæ–°ï¼Œä¸ç¨³å®š)

---

**æœ€ç»ˆç»“è®º**: ä½ çš„åˆ¤æ–­å®Œå…¨æ­£ç¡®ï¼ä¿æŒ KaVa é£æ ¼ï¼Œåªåš**é’ˆå¯¹æ€§çš„å°æ”¹è¿›**å’Œ**å¯¹æ ‡ç›¸å…³é¢†åŸŸçš„ SOTA æ–¹æ³•**ï¼ˆGOVERN, MT-KDï¼‰ï¼Œè€Œä¸æ˜¯ç›²ç›®è¿½æ±‚å…¶ä»–é¢†åŸŸçš„æ–°æ–¹æ³•ã€‚

---

**æœ€åæ›´æ–°**: 2025å¹´11æœˆ18æ—¥
