# ğŸš€ KAVA è®­ç»ƒå¿«é€Ÿå¯åŠ¨æŒ‡å—

## âœ… ç¯å¢ƒå·²å°±ç»ª

æ‚¨çš„ç¯å¢ƒé…ç½®ï¼š
- âœ… PyTorch: 2.5.1+cu121 (CUDA 12.1)
- âœ… CUDA Available: True
- âœ… GPU: NVIDIA GeForce RTX 4070 Laptop GPU (8GB)
- âœ… æ¨¡å‹: local_models/ (Teacher 1.5B + Student 0.5B)
- âœ… æ•°æ®: local_data/gsm8k/ (7473 è®­ç»ƒæ ·æœ¬)

---

## ğŸ¯ å¯åŠ¨è®­ç»ƒï¼ˆä¸€é”®å¯åŠ¨ï¼‰

```bash
python train_simplified.py
```

---

## ğŸ“Š é¢„æœŸè¾“å‡ºæµç¨‹

### Phase 1: åˆå§‹åŒ–ï¼ˆ1-2 åˆ†é’Ÿï¼‰

```
ğŸš€ğŸš€ğŸš€ Starting KAVA Training with Local Resources ğŸš€ğŸš€ğŸš€

ğŸ“‹ Environment Check:
   Python: 3.11.x
   PyTorch: 2.5.1+cu121
   CUDA Available: True
   CUDA Device: NVIDIA GeForce RTX 4070 Laptop GPU
   CUDA Memory: 8.0 GB

ğŸ¯ KAVA Local Training - Simplified & Stable

âš™ï¸ Configuration:
   Teacher: local_models/qwen-1.5b-teacher
   Student: local_models/qwen-0.5b-student
   Dataset: local_data/gsm8k
   Device: cuda
   Effective Batch Size: 32

ğŸ“š Step 1: Loading Dataset
   âœ… Dataset loaded: 7473 samples

ğŸ”¤ Step 2: Loading Tokenizer
   âœ… Tokenizer loaded

ğŸ”§ Step 3: Processing Dataset
   âœ… 3737 batches prepared
```

### Phase 2: æ¨¡å‹åŠ è½½ï¼ˆ2-3 åˆ†é’Ÿï¼‰

```
ğŸ¤– Step 4: Loading Models
   Loading Teacher (4-bit quantized)...
      âœ… Teacher: d_model=1536
   Loading Student (bfloat16)...
      âœ… Student: d_model=896
```

**æ˜¾å­˜å ç”¨é¢„æœŸ**:
- Teacher (4-bit): ~1.2 GB
- Student (bf16): ~1.0 GB
- Projector: ~0.3 GB
- æ¿€æ´»å€¼: ~3.5 GB
- **æ€»è®¡**: ~6 GB / 8 GB âœ… å®‰å…¨

### Phase 3: è®­ç»ƒå¼€å§‹

```
ğŸ—ºï¸ Step 5: Initializing KAVA Components
   Projector: 1536 -> 896
   Loss: Mercator (alpha=1.0, beta=0.01)

======================================================================
ğŸ¯ Training Start - Monitor 'CosSim' (Target: >0.90)
======================================================================

Training:   0%|          | 0/3737 [00:00<?, ?it/s]
```

### Phase 4: è®­ç»ƒè¿›åº¦ï¼ˆæ ¸å¿ƒç›‘æ§ï¼‰

```
Training:   1%|â–         | 16/3737 [00:45<2:15:30, 0.45it/s]
Loss: 0.8234 | CosSim: 0.1766 | Status: ğŸ”„ Adapting

[Step 0050] Loss: 0.4521 | CosSim: 0.5479 âš ï¸ Learning
Training:   3%|â–         | 100/3737 [03:40<2:01:23, 0.50it/s]

[Step 0100] Loss: 0.2145 | CosSim: 0.7855 ğŸ“ˆ Good
Training:   5%|â–Œ         | 200/3737 [07:20<1:58:45, 0.50it/s]

[Step 0200] Loss: 0.0432 | CosSim: 0.9568 âœ… Excellent
ğŸ’¾ Checkpoint saved: checkpoints/proj_step_200.pth
```

---

## ğŸ¯ å…³é”®æŒ‡æ ‡è§£è¯»

### Cosine Similarity (CosSim) - æœ€é‡è¦ï¼

| CosSim å€¼ | çŠ¶æ€ | å«ä¹‰ | å¯¹åº” Loss |
|----------|------|------|----------|
| 0.10-0.30 | ğŸ”„ Adapting | åˆå§‹éšæœºçŠ¶æ€ | 0.7-0.9 |
| 0.30-0.50 | ğŸ”„ Adapting | å¼€å§‹å­¦ä¹  | 0.5-0.7 |
| 0.50-0.70 | âš ï¸ Learning | å¿«é€Ÿè¿›æ­¥ä¸­ | 0.3-0.5 |
| 0.70-0.90 | ğŸ“ˆ Good | æ˜¾è‘—å¯¹é½ | 0.1-0.3 |
| 0.90-0.95 | ğŸ¯ Great | æ¥è¿‘ç›®æ ‡ | 0.05-0.1 |
| **>0.95** | **âœ… Excellent** | **å®Œç¾å¯¹é½ï¼** | **<0.05** |

### è®­ç»ƒé€Ÿåº¦é¢„æœŸ

- **è¿­ä»£é€Ÿåº¦**: ~0.4-0.5 it/s (æ¯æ¬¡è¿­ä»£ 2-2.5 ç§’)
- **æ¢¯åº¦ç´¯ç§¯**: æ¯ 16 ä¸ª batch æ›´æ–°ä¸€æ¬¡
- **å®é™…æ›´æ–°é€Ÿåº¦**: æ¯ 32-40 ç§’ä¸€æ¬¡æƒé‡æ›´æ–°
- **æ¯ 50 æ­¥**: ~25-30 åˆ†é’Ÿ
- **æ¯ 200 æ­¥**: ~1.5-2 å°æ—¶
- **å®Œæ•´ Epoch**: ~3-4 å°æ—¶

---

## âš ï¸ å¯èƒ½é‡åˆ°çš„æƒ…å†µ

### æƒ…å†µ 1: æ˜¾å­˜ä¸è¶³ (OOM)

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate X GB
```

**è§£å†³æ–¹æ¡ˆ**: æ‰“å¼€ `train_simplified.py`ï¼Œä¿®æ”¹é…ç½®ï¼š
```python
CONFIG = {
    "batch_size": 1,                      # ä» 2 æ”¹ä¸º 1
    "gradient_accumulation_steps": 32,    # ä» 16 æ”¹ä¸º 32
}
```

### æƒ…å†µ 2: CosSim ä¸ä¸Šå‡

**ç—‡çŠ¶**: 200 æ­¥å CosSim ä» <0.50

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡è¿‡ä½
2. æ•°æ®å¤„ç†é—®é¢˜

**è°ƒè¯•**: æ£€æŸ¥æ¯ 50 æ­¥çš„è¾“å‡ºï¼Œè§‚å¯Ÿè¶‹åŠ¿ã€‚

### æƒ…å†µ 3: Loss éœ‡è¡

**ç—‡çŠ¶**: Loss ä¸Šä¸‹æ³¢åŠ¨å‰§çƒˆ

**è§£å†³**: é™ä½ `lr_projector` ä» 1e-3 åˆ° 5e-4

---

## ğŸ›‘ åœæ­¢è®­ç»ƒ

### ä¼˜é›…åœæ­¢
- **æŒ‰ Ctrl+C ä¸€æ¬¡**: ä¿å­˜ç´§æ€¥æ£€æŸ¥ç‚¹åé€€å‡º
- æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: `checkpoints/emergency_projector.pth`

### ç»§ç»­è®­ç»ƒ
è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨ä¿å­˜æ£€æŸ¥ç‚¹ï¼Œä½†ä¸æ”¯æŒè‡ªåŠ¨æ¢å¤ã€‚å¦‚éœ€ç»§ç»­è®­ç»ƒï¼Œéœ€è¦ä¿®æ”¹è„šæœ¬åŠ è½½æ£€æŸ¥ç‚¹ã€‚

---

## âœ… è®­ç»ƒå®Œæˆæ ‡å¿—

```
======================================================================
âœ… Training Complete!
======================================================================

ğŸ’¾ Final models saved:
   - final_projector.pth
   - final_student/

ğŸ‰ All Done!
```

**æœ€ç»ˆæ–‡ä»¶**:
- `final_projector.pth`: è®­ç»ƒå¥½çš„ Elastic Bottleneck
- `final_student/`: è’¸é¦åçš„ Student æ¨¡å‹
- `checkpoints/proj_step_*.pth`: ä¸­é—´æ£€æŸ¥ç‚¹

---

## ğŸ” å®æ—¶ç›‘æ§æŠ€å·§

### æ–¹æ³• 1: è§‚å¯Ÿè¿›åº¦æ¡
```
Training:   5%|â–Œ  | 200/3737 [07:20<1:58:45, 0.50it/s]
Loss: 0.0432 | CosSim: 0.9568 | Status: âœ… Excellent
```

### æ–¹æ³• 2: æ¯ 50 æ­¥è¯¦ç»†è¾“å‡º
```
[Step 0050] Loss: 0.4521 | CosSim: 0.5479 âš ï¸ Learning
[Step 0100] Loss: 0.2145 | CosSim: 0.7855 ğŸ“ˆ Good
[Step 0150] Loss: 0.1234 | CosSim: 0.8766 ğŸ“ˆ Good
[Step 0200] Loss: 0.0432 | CosSim: 0.9568 âœ… Excellent
```

### æ–¹æ³• 3: GPU ç›‘æ§ï¼ˆå¦å¼€ç»ˆç«¯ï¼‰
```powershell
nvidia-smi -l 5
```
æŒç»­æ˜¾ç¤º GPU ä½¿ç”¨ç‡å’Œæ˜¾å­˜å ç”¨ã€‚

---

## ğŸ‰ æˆåŠŸæ ‡å‡†

è®­ç»ƒæˆåŠŸçš„æ ‡å¿—ï¼š
1. âœ… **CosSim è¾¾åˆ° 0.95+**ï¼ˆExcellent çŠ¶æ€ï¼‰
2. âœ… **Loss é™è‡³ 0.05 ä»¥ä¸‹**
3. âœ… **è®­ç»ƒç¨³å®š**ï¼ˆæ—  NaNã€æ—  OOMï¼‰
4. âœ… **æ£€æŸ¥ç‚¹ä¿å­˜æˆåŠŸ**

---

## ğŸ“ è®­ç»ƒæ—¥å¿—è®°å½•

å»ºè®®è®°å½•ä»¥ä¸‹ä¿¡æ¯ï¼š
- å¼€å§‹æ—¶é—´
- CosSim åœ¨ 50/100/200 æ­¥çš„å€¼
- æœ€ç»ˆ CosSim å’Œ Loss
- è®­ç»ƒæ€»æ—¶é•¿
- æ˜¯å¦é‡åˆ°é—®é¢˜

---

## ğŸš€ ç°åœ¨å¼€å§‹ï¼

ç¡®è®¤ä»¥ä¸‹å‡†å¤‡å°±ç»ªï¼š
- [x] PyTorch CUDA å·²å®‰è£…ï¼ˆ2.5.1+cu121ï¼‰
- [x] GPU å¯ç”¨ï¼ˆRTX 4070ï¼‰
- [x] æ¨¡å‹å’Œæ•°æ®é›†å·²ä¸‹è½½
- [x] è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»

**å¯åŠ¨å‘½ä»¤**:
```bash
python train_simplified.py
```

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸ‰ æœŸå¾… CosSim çªç ´ 0.95ï¼
