"""
æµ‹è¯• HPC å¯è§†åŒ–å·¥å…·
åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®å¹¶ç”Ÿæˆç¤ºä¾‹ HTML æŠ¥å‘Š
"""

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from visualization.hpc_visualizer import HPCVisualizer
import json
import numpy as np

def create_mock_data():
    """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®"""
    print("Creating mock data...")
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ—¥å¿—
    training_log = {
        'step': list(range(0, 5000, 100)),
        'train_loss': [2.5 - i * 0.0003 + np.random.random() * 0.1 for i in range(50)],
        'eval_loss': [2.3 - i * 0.00025 + np.random.random() * 0.15 for i in range(50)],
        'kv_loss': [1.2 - i * 0.00015 + np.random.random() * 0.05 for i in range(50)],
        'learning_rate': [2e-5 * (1 - i/50) for i in range(50)],
        'grad_norm': [1.5 - i * 0.02 + np.random.random() * 0.3 for i in range(50)],
    }
    
    # æ¨¡æ‹Ÿè·¯ç”±æƒé‡
    routing_weights = {
        'teacher_names': ['Qwen2.5-7B', 'Qwen2.5-14B'],
        'steps': list(range(0, 5000, 100)),
        'weights': [[0.5 + (i/50) * 0.2 * np.random.random(), 
                     0.5 - (i/50) * 0.2 * np.random.random()] 
                    for i in range(50)],
    }
    
    # æ¨¡æ‹Ÿè¯„æµ‹ç»“æœ
    eval_results = {
        'gsm8k_test': {'score': 75.3, 'metric': 'exact_match', 'num_examples': 1319},
        'math500': {'score': 42.1, 'metric': 'exact_match', 'num_examples': 500},
        'bbh': {'score': 68.5, 'metric': 'exact_match', 'num_examples': 1000},
        'gpqa': {'score': 35.2, 'metric': 'accuracy', 'num_examples': 448},
        'truthfulqa': {'score': 52.8, 'metric': 'accuracy', 'num_examples': 817},
        'cmmlu_subset': {'score': 63.4, 'metric': 'accuracy', 'num_examples': 1000},
        'ceval_subset': {'score': 61.9, 'metric': 'accuracy', 'num_examples': 1000},
        'average': 57.0,
    }
    
    # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
    test_dir = Path('./test_visualization_data')
    test_dir.mkdir(exist_ok=True)
    
    with open(test_dir / 'training_log.json', 'w') as f:
        json.dump(training_log, f, indent=2)
    
    with open(test_dir / 'routing_weights.json', 'w') as f:
        json.dump(routing_weights, f, indent=2)
    
    with open(test_dir / 'eval_results.json', 'w') as f:
        json.dump(eval_results, f, indent=2)
    
    print(f"âœ“ Mock data created in: {test_dir}")
    return test_dir


def test_training_curves(visualizer, data_dir):
    """æµ‹è¯•è®­ç»ƒæ›²çº¿å¯è§†åŒ–"""
    print("\n" + "="*60)
    print("Testing Training Curves Visualization")
    print("="*60)
    
    html_path = visualizer.plot_training_curves(
        log_file=str(data_dir / 'training_log.json'),
        output_name='test_training_curves',
    )
    
    if html_path:
        print(f"âœ“ Training curves HTML: {html_path}")
        return True
    return False


def test_routing_weights(visualizer, data_dir):
    """æµ‹è¯•è·¯ç”±æƒé‡å¯è§†åŒ–"""
    print("\n" + "="*60)
    print("Testing Routing Weights Visualization")
    print("="*60)
    
    html_path = visualizer.plot_routing_weights(
        weights_file=str(data_dir / 'routing_weights.json'),
        output_name='test_routing_weights',
    )
    
    if html_path:
        print(f"âœ“ Routing weights HTML: {html_path}")
        return True
    return False


def test_evaluation_results(visualizer, data_dir):
    """æµ‹è¯•è¯„æµ‹ç»“æœå¯è§†åŒ–"""
    print("\n" + "="*60)
    print("Testing Evaluation Results Visualization")
    print("="*60)
    
    # åˆ›å»ºå¤šä¸ªæ¨¡å‹çš„è¯„æµ‹ç»“æœï¼ˆæ¨¡æ‹Ÿå¯¹æ¯”ï¼‰
    eval_file = data_dir / 'eval_results.json'
    
    html_path = visualizer.plot_evaluation_results(
        eval_files=[str(eval_file)],
        labels=['Test Model'],
        output_name='test_evaluation',
    )
    
    if html_path:
        print(f"âœ“ Evaluation results HTML: {html_path}")
        return True
    return False


def test_experiment_summary(visualizer, data_dir):
    """æµ‹è¯•ç»¼åˆæŠ¥å‘Š"""
    print("\n" + "="*60)
    print("Testing Experiment Summary")
    print("="*60)
    
    html_path = visualizer.create_experiment_summary(
        experiment_dir=str(data_dir),
        output_name='test_summary',
    )
    
    if html_path:
        print(f"âœ“ Experiment summary HTML: {html_path}")
        return True
    return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("="*60)
    print("HPC Visualizer Test Suite")
    print("="*60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    data_dir = create_mock_data()
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    output_dir = './test_visualizations'
    visualizer = HPCVisualizer(output_dir=output_dir)
    print(f"\nOutput directory: {output_dir}")
    
    # è¿è¡Œæµ‹è¯•
    results = {
        'Training Curves': test_training_curves(visualizer, data_dir),
        'Routing Weights': test_routing_weights(visualizer, data_dir),
        'Evaluation Results': test_evaluation_results(visualizer, data_dir),
        'Experiment Summary': test_experiment_summary(visualizer, data_dir),
    }
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("Test Results Summary")
    print("="*60)
    
    all_passed = True
    for test_name, passed in results.items():
        status = "âœ“ PASSED" if passed else "âœ— FAILED"
        print(f"{test_name:30s} {status}")
        if not passed:
            all_passed = False
    
    print("="*60)
    
    if all_passed:
        print("\nâœ“ All tests passed!")
        print(f"\nğŸ“Š Generated visualizations in: {output_dir}/")
        print("\nTo view the results:")
        print(f"  1. Open {output_dir}/test_summary.html in your browser")
        print(f"  2. Or check individual HTML files in {output_dir}/")
        
        # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
        from pathlib import Path
        html_files = list(Path(output_dir).glob("*.html"))
        png_files = list(Path(output_dir).glob("*.png"))
        
        print(f"\nGenerated files:")
        print(f"  HTML: {len(html_files)} files")
        print(f"  PNG:  {len(png_files)} files")
        
        for html_file in html_files:
            print(f"    - {html_file.name}")
        
        return 0
    else:
        print("\nâœ— Some tests failed!")
        return 1


if __name__ == "__main__":
    exit(main())
